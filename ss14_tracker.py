"""
SS14 è‡ªåŠ¨åŒ–æ±‰åŒ–å·¥å…·ç®± v3.2
==========================
æ”¯æŒ GUI å’Œå‘½ä»¤è¡Œä¸¤ç§æ¨¡å¼ï¼Œé›†æˆæå–ã€åŒæ­¥ã€åˆå¹¶åŠŸèƒ½ã€‚

ä¼˜åŒ–ç‰¹æ€§:
- ä¸€é”®å·¥ä½œæµ
- ç›®å½•è‡ªåŠ¨æ£€æµ‹
- è¿›åº¦æ¡
- API è¯·æ±‚é‡è¯•
- å¯é…ç½®å­—æ®µåˆ—è¡¨
- é«˜DPIå±å¹•æ”¯æŒ
- å¢é‡æå–æ¨¡å¼
"""

import os
import sys
import json
import argparse
import subprocess
import threading
import io
import time
import hashlib
import requests
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable, Set
from collections import defaultdict, deque
import logging
from logging.handlers import TimedRotatingFileHandler

# ==================== æ—¥å¿—é…ç½® (Logging) ====================

class GuiHandler(logging.Handler):
    """
    è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨ï¼Œå°†æ—¥å¿—å‘é€åˆ° GUIã€‚
    ä½¿ç”¨é˜Ÿåˆ—ç¼“å­˜æ—¥å¿—ï¼Œç›´åˆ° GUI å‡†å¤‡å¥½æ˜¾ç¤ºã€‚
    """
    def __init__(self, max_len=5000):
        super().__init__()
        self.log_buffer = deque(maxlen=max_len)
        self.gui_callback = None

    def emit(self, record):
        try:
            msg = self.format(record)
            # ä¿å­˜æ—¥å¿—çº§åˆ«å’Œæ¶ˆæ¯ï¼Œä»¥ä¾¿ GUI è¿›è¡Œé¢œè‰²é«˜äº®
            self.log_buffer.append((record.levelname, msg))
            if self.gui_callback:
                self.gui_callback()
        except Exception:
            self.handleError(record)
            
    def set_callback(self, callback):
        self.gui_callback = callback
        
    def pop_logs(self):
        """è·å–å¹¶æ¸…é™¤æ‰€æœ‰ç¼“å­˜çš„æ—¥å¿—"""
        logs = list(self.log_buffer)
        self.log_buffer.clear()
        return logs

# å…¨å±€ GUI æ—¥å¿—å¤„ç†å™¨å®ä¾‹
gui_log_handler = GuiHandler()

def setup_logging():
    """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / f"ss14_tracker_{datetime.now().strftime('%Y-%m-%d')}.log"
    
    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤æ—§çš„å¤„ç†å™¨ï¼ˆé˜²æ­¢é‡å¤ï¼‰
    if logger.handlers:
        logger.handlers.clear()
    
    # 1. æ–‡ä»¶å¤„ç†å™¨ (è‡ªåŠ¨æŒ‰å¤©åˆ‡å‰²ï¼Œä¿ç•™30å¤©)
    file_handler = TimedRotatingFileHandler(
        log_file, when="midnight", interval=1, backupCount=30, encoding='utf-8'
    )
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%H:%M:%S')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # 2. æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # 3. GUI å¤„ç†å™¨
    # GUI æ—¥å¿—ä¸éœ€è¦æ—¶é—´æˆ³ï¼ˆGUI è‡ªå·±ä¼šåŠ æˆ–è€…å·²ç»åŒ…å«äº†ï¼‰ï¼Œè¿™é‡Œä¸ºäº†ç»Ÿä¸€æ ¼å¼ï¼Œç®€å•å¤„ç†
    # å¦‚æœ GUI éœ€è¦æ ¹æ®å†…å®¹é«˜äº®ï¼Œæˆ‘ä»¬åœ¨ emit ä¸­å·²ç»ä¿å­˜äº† levelname
    gui_log_handler.setFormatter(logging.Formatter('%(message)s'))
    logger.addHandler(gui_log_handler)
    
    logging.info(f"æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œæ—¥å¿—æ–‡ä»¶: {log_file}")


# ==================== é«˜ DPI æ”¯æŒ (Windows) ====================
# åœ¨å¯¼å…¥ tkinter ä¹‹å‰è®¾ç½® DPI æ„ŸçŸ¥ï¼Œè§£å†³ 2K/4K å±å¹•å­—ä½“æ¨¡ç³Šé—®é¢˜

def enable_high_dpi():
    """å¯ç”¨ Windows é«˜ DPI æ”¯æŒ"""
    if sys.platform == 'win32':
        try:
            from ctypes import windll
            # è®¾ç½®è¿›ç¨‹çº§åˆ«çš„ DPI æ„ŸçŸ¥
            # PROCESS_PER_MONITOR_DPI_AWARE = 2
            windll.shcore.SetProcessDpiAwareness(2)
        except Exception:
            try:
                # å›é€€åˆ°æ—§ç‰ˆ API
                windll.user32.SetProcessDPIAware()
            except Exception:
                pass

# åœ¨åŠ è½½ GUI å‰è°ƒç”¨
enable_high_dpi()

# ==================== å¸¸é‡é…ç½® (Constants) ====================

# é»˜è®¤å¯ç¿»è¯‘å­—æ®µåˆ—è¡¨ï¼ˆå¯åœ¨é…ç½®ä¸­ä¿®æ”¹ï¼‰
DEFAULT_TRANSLATABLE_FIELDS = ['name', 'description']

# API é‡è¯•é…ç½®
API_RETRY_COUNT = 3
API_RETRY_DELAY = 2  # ç§’

# é…ç½®æ–‡ä»¶å
CONFIG_FILE = "config.json"

# æå–è¾“å‡ºç›®å½•ï¼ˆç”¨äºæŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æ¨¡å¼ï¼‰
EXTRACT_OUTPUT_DIR = "extracted"

# ==================== FTL é”®æ£€æµ‹ (FTL Key Detection) ====================

def is_ftl_key(text: str) -> bool:
    """
    æ£€æµ‹å­—ç¬¦ä¸²æ˜¯å¦ä¸º FTL æœ¬åœ°åŒ–é”®ã€‚
    
    FTL é”®ç‰¹å¾ï¼š
    - ä¸åŒ…å«ç©ºæ ¼
    - åŒ…å«è¿å­—ç¬¦ -
    - æ ¼å¼å¦‚ "word-word-word" æˆ– "word-word-Word"ï¼ˆkebab-case é£æ ¼ï¼‰
    - è‡³å°‘æœ‰3æ®µï¼ˆ2ä¸ªè¿å­—ç¬¦ï¼‰
    
    æ­£å¸¸æ–‡æœ¬ç‰¹å¾ï¼ˆä¸åº”è¿‡æ»¤ï¼‰ï¼š
    - åŒ…å«ç©ºæ ¼ï¼ˆå¦‚ "Pride-O-Mat restock box"ï¼‰
    - åªæœ‰1-2æ®µè¿å­—ç¬¦è¿æ¥ï¼ˆå¦‚ "AK-47"ï¼‰
    - åŒ…å«éå­—æ¯å­—ç¬¦ï¼ˆæ•°å­—ã€ç‰¹æ®Šç¬¦å·ç­‰ï¼‰
    
    ç¤ºä¾‹ï¼š
    - "loadout-group-weapon" -> True (FTL é”®)
    - "item-component-size-Tiny" -> True (FTL é”®)
    - "Pride-O-Mat restock box" -> False (åŒ…å«ç©ºæ ¼ï¼Œæ˜¯æ­£å¸¸æ–‡æœ¬)
    - "AK-47" -> False (åªæœ‰2æ®µï¼Œä¸æ˜¯ FTL é”®)
    - "Assault Rifle" -> False (æ— è¿å­—ç¬¦)
    """
    if not text or not isinstance(text, str):
        return False
    
    text = text.strip()
    
    # æ­£å¸¸æ–‡æœ¬åŒ…å«ç©ºæ ¼ï¼Œç›´æ¥æ”¾è¡Œ
    if ' ' in text:
        return False
    
    # å¿…é¡»åŒ…å«è¿å­—ç¬¦
    if '-' not in text:
        return False
    
    # åˆ†å‰²ä¸ºæ®µ
    parts = text.split('-')
    
    # FTL é”®é€šå¸¸è‡³å°‘æœ‰3æ®µï¼ˆå¦‚ xxx-yyy-zzzï¼‰
    # åªæœ‰2æ®µçš„å¦‚ "AK-47" æˆ– "O-Mat" ä¸å¤ªå¯èƒ½æ˜¯ FTL é”®
    if len(parts) < 3:
        return False
    
    # æ£€æŸ¥æ¯æ®µæ˜¯å¦ä¸ºçº¯å­—æ¯ï¼ˆFTL é”®æ¯æ®µéƒ½æ˜¯å•è¯ï¼‰
    for part in parts:
        # å…è®¸ç©ºæ®µï¼ˆå¦‚ xxx--yyyï¼‰ä¹Ÿè§†ä¸º FTL é”®
        if part and not part.isalpha():
            return False
    
    return True

# ==================== ä¸­æ–‡æ£€æµ‹ (Chinese Detection) ====================

def contains_chinese(text: str) -> bool:
    """
    æ£€æµ‹å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ã€‚
    ç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æ ‡è®°ä¸ºå·²ç¿»è¯‘çŠ¶æ€ã€‚
    
    CJKç»Ÿä¸€æ±‰å­—èŒƒå›´ï¼š\u4e00-\u9fff
    """
    if not text or not isinstance(text, str):
        return False
    return any('\u4e00' <= c <= '\u9fff' for c in text)

# ==================== å…±äº«å·¥å…· (Utils) ====================

# å…¨å±€è¿›åº¦å›è°ƒï¼ˆç”¨äº GUI æ›´æ–°è¿›åº¦æ¡ï¼‰
_progress_callback: Optional[Callable[[int, int, str], None]] = None
# å…¨å±€åœæ­¢æ£€æŸ¥å›è°ƒï¼ˆç”¨äºé•¿æ—¶é—´æ“ä½œæ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢ï¼‰
_stop_check_callback: Optional[Callable[[], bool]] = None

def set_progress_callback(callback: Optional[Callable[[int, int, str], None]]):
    """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•° (current, total, message)"""
    global _progress_callback
    _progress_callback = callback

def set_stop_check_callback(callback: Optional[Callable[[], bool]]):
    """è®¾ç½®åœæ­¢æ£€æŸ¥å›è°ƒå‡½æ•°ï¼Œè¿”å› True è¡¨ç¤ºéœ€è¦åœæ­¢"""
    global _stop_check_callback
    _stop_check_callback = callback

def should_stop() -> bool:
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢å½“å‰æ“ä½œ"""
    if _stop_check_callback:
        return _stop_check_callback()
    return False

def report_progress(current: int, total: int, message: str = ""):
    """æŠ¥å‘Šè¿›åº¦"""
    if _progress_callback:
        _progress_callback(current, total, message)

def log(message: str, level: str = "INFO"):
    """
    å…¼å®¹æ—§ä»£ç çš„æ—¥å¿—é€‚é…å™¨ï¼Œè½¬å‘åˆ° logging æ¨¡å—ã€‚
    """
    lvl_name = level.upper()
    # æ˜ å°„è‡ªå®šä¹‰çº§åˆ«åç§°åˆ° logging çº§åˆ«
    if lvl_name == "ERROR":
        lvl = logging.ERROR
    elif lvl_name == "WARNING":
        lvl = logging.WARNING
    elif lvl_name == "DEBUG":
        lvl = logging.DEBUG
    else:
        lvl = logging.INFO
    
    logging.log(lvl, message)

def error(message: str):
    """è¾“å‡ºé”™è¯¯å¹¶é€€å‡º"""
    log(message, "ERROR")
    sys.exit(1)

def detect_game_directory() -> Optional[str]:
    """
    è‡ªåŠ¨æ£€æµ‹æ¸¸æˆç›®å½•ã€‚
    æ£€æŸ¥å¸¸è§çš„ SS14 ç›®å½•ç»“æ„ã€‚
    """
    candidates = [
        "Resources/Prototypes",
        "Content/Resources/Prototypes",
        "Resources",
        "Content",
    ]
    
    for candidate in candidates:
        if os.path.isdir(candidate):
            log(f"è‡ªåŠ¨æ£€æµ‹åˆ°æ¸¸æˆç›®å½•: {candidate}")
            return candidate
    
    return None

# ==================== YAML å¤„ç†å™¨ (YAML Processor) ====================

try:
    from ruamel.yaml import YAML
    HAS_RUAMEL = True
except ImportError:
    HAS_RUAMEL = False
    import yaml

class YAMLProcessor:
    """YAML å¤„ç†å™¨ - ä½¿ç”¨ ruamel.yaml ä¿ç•™æ³¨é‡Šã€æ ¼å¼å’Œè‡ªå®šä¹‰æ ‡ç­¾ã€‚"""
    
    def __init__(self):
        if HAS_RUAMEL:
            self._yaml = YAML()
            self._yaml.preserve_quotes = True
            self._yaml.width = 4096  # é˜²æ­¢è‡ªåŠ¨æ¢è¡Œ
            self._yaml.default_flow_style = None  # ä¿ç•™åŸå§‹æµå¼æ ·å¼
            self._yaml.allow_duplicate_keys = True
            self._yaml.indent(mapping=2, sequence=4, offset=2)
        else:
            self._yaml = None
            print("è­¦å‘Š: æœªæ‰¾åˆ° ruamel.yamlã€‚å›é€€åˆ°åŸºç¡€ PyYAMLï¼ˆå°†ä¸¢å¤±æ ¼å¼ï¼‰ã€‚")
    
    def load(self, file_path: str) -> Any:
        """åŠ è½½ YAML æ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            if HAS_RUAMEL:
                return self._yaml.load(f)
            else:
                return yaml.safe_load(f)
    
    def dump(self, data: Any, file_path: str):
        """ä¿å­˜ YAML æ–‡ä»¶ï¼ˆä¿ç•™æ ¼å¼ï¼‰"""
        with open(file_path, 'w', encoding='utf-8') as f:
            if HAS_RUAMEL:
                self._yaml.dump(data, f)
            else:
                yaml.dump(data, f, allow_unicode=True, sort_keys=False, 
                         default_flow_style=False, indent=2)

    def load_from_string(self, content: str) -> Any:
        """ä»å­—ç¬¦ä¸²åŠ è½½ YAML"""
        if HAS_RUAMEL:
            return self._yaml.load(io.StringIO(content))
        else:
            return yaml.safe_load(content)

# ==================== Paratranz å®¢æˆ·ç«¯ (PZ Client) ====================

class PZClient:
    """
    Paratranz API å®¢æˆ·ç«¯
    æ ¹æ®å®˜æ–¹æ–‡æ¡£å®ç°ï¼šhttps://paratranz.cn/docs
    """
    BASE_URL = "https://paratranz.cn/api"

    def __init__(self, project_id: int, token: str):
        self.project_id = project_id
        self.token = token
        # å®˜æ–¹æ–‡æ¡£è¦æ±‚ï¼šAuthorization: Bearer {TOKEN}
        self.headers = {"Authorization": f"Bearer {token}"}
        if not project_id or not token:
            raise ValueError("éœ€è¦æä¾› Project ID å’Œ Token")
        log(f"åˆå§‹åŒ– Paratranz å®¢æˆ·ç«¯: é¡¹ç›®ID={project_id}")

    def _request_with_retry(self, method: str, url: str, **kwargs) -> requests.Response:
        """å¸¦é‡è¯•çš„è¯·æ±‚"""
        # HTTP çŠ¶æ€ç è¯´æ˜ï¼ˆå‚è€ƒ Paratranz API æ–‡æ¡£ï¼‰
        STATUS_CODES = {
            200: "æˆåŠŸ",
            201: "åˆ›å»ºæˆåŠŸ",
            302: "é‡å®šå‘",
            400: "å‚æ•°é”™è¯¯",
            401: "Token é”™è¯¯æˆ–è¿‡æœŸ",
            403: "æ²¡æœ‰æƒé™",
            404: "èµ„æºä¸å­˜åœ¨",
            405: "HTTPæ–¹æ³•é”™è¯¯",
            429: "è¯·æ±‚è¿‡äºé¢‘ç¹",
            500: "æœåŠ¡å™¨é”™è¯¯",
            502: "æœåŠ¡å™¨æ— å“åº”",
            503: "æœåŠ¡ä¸å¯ç”¨",
            504: "æœåŠ¡è¶…æ—¶"
        }
        
        last_error = None
        for attempt in range(API_RETRY_COUNT):
            try:
                log(f"å‘é€è¯·æ±‚: {method} {url}")
                response = requests.request(method, url, headers=self.headers, timeout=30, **kwargs)
                
                # è·å–çŠ¶æ€ç è¯´æ˜
                status_desc = STATUS_CODES.get(response.status_code, "æœªçŸ¥çŠ¶æ€")
                log(f"å“åº”çŠ¶æ€ç : {response.status_code} ({status_desc})")
                
                # å¤„ç†å¸¸è§é”™è¯¯
                if response.status_code == 401:
                    log("âŒ [401] Token é”™è¯¯æˆ–å·²è¿‡æœŸï¼Œè¯·æ£€æŸ¥ä½ çš„ API Token", "ERROR")
                    return response
                
                if response.status_code == 403:
                    log("âŒ [403] æ²¡æœ‰æƒé™è®¿é—®è¯¥èµ„æº", "ERROR")
                    return response
                
                if response.status_code == 404:
                    log("âŒ [404] èµ„æºä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥é¡¹ç›®IDæ˜¯å¦æ­£ç¡®", "ERROR")
                    return response
                
                if response.status_code == 400:
                    try:
                        error_msg = response.json().get('message', response.text[:100])
                    except:
                        error_msg = response.text[:100]
                    log(f"âŒ [400] å‚æ•°é”™è¯¯: {error_msg}", "ERROR")
                    return response
                
                if response.status_code >= 500:
                    log(f"âš ï¸ [{response.status_code}] æœåŠ¡å™¨é”™è¯¯ï¼Œå¯èƒ½éœ€è¦ç¨åé‡è¯•", "WARNING")
                    return response
                
                # å¤„ç†é€Ÿç‡é™åˆ¶
                if response.status_code == 429:
                    wait_time = int(response.headers.get('Retry-After', API_RETRY_DELAY * 2))
                    log(f"âš ï¸ [429] API é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...", "WARNING")
                    time.sleep(wait_time)
                    continue
                
                return response
                
            except requests.exceptions.RequestException as e:
                last_error = e
                log(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}", "ERROR")
                if attempt < API_RETRY_COUNT - 1:
                    log(f"â³ {API_RETRY_DELAY} ç§’åé‡è¯• ({attempt + 1}/{API_RETRY_COUNT})...", "WARNING")
                    time.sleep(API_RETRY_DELAY)
                    
        raise last_error if last_error else Exception("è¯·æ±‚å¤±è´¥")

    def test_connection(self) -> bool:
        """æµ‹è¯• API è¿æ¥å’Œ Token æœ‰æ•ˆæ€§"""
        log("æ­£åœ¨æµ‹è¯• API è¿æ¥...")
        try:
            url = f"{self.BASE_URL}/projects/{self.project_id}"
            response = self._request_with_retry("GET", url)
            
            if response.status_code == 200:
                data = response.json()
                project_name = data.get('name', 'æœªçŸ¥')
                log(f"âœ… è¿æ¥æˆåŠŸï¼é¡¹ç›®åç§°: {project_name}")
                return True
            elif response.status_code == 401:
                log("âŒ Token æ— æ•ˆæˆ–å·²è¿‡æœŸ", "ERROR")
                return False
            elif response.status_code == 404:
                log(f"âŒ é¡¹ç›® ID {self.project_id} ä¸å­˜åœ¨", "ERROR")
                return False
            else:
                try:
                    error_msg = response.json().get('message', response.text)
                except:
                    error_msg = response.text
                log(f"âŒ è¿æ¥å¤±è´¥ ({response.status_code}): {error_msg}", "ERROR")
                return False
        except Exception as e:
            log(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}", "ERROR")
            return False

    def get_file_id(self, filename: str, remote_path: str = "/") -> Optional[int]:
        """
        é€šè¿‡æ–‡ä»¶åå’Œè·¯å¾„è·å–æ–‡ä»¶ID
        
        å‚æ•°:
            filename: æ–‡ä»¶å
            remote_path: è¿œç¨‹è·¯å¾„ï¼ˆç”¨äºç²¾ç¡®åŒ¹é…ï¼Œé¿å…åŒåæ–‡ä»¶å†²çªï¼‰
        """
        url = f"{self.BASE_URL}/projects/{self.project_id}/files"
        try:
            response = self._request_with_retry("GET", url)
            if response.status_code != 200:
                log(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {response.text}", "ERROR")
                return None
                
            files = response.json()
            log(f"é¡¹ç›®ä¸­å…±æœ‰ {len(files)} ä¸ªæ–‡ä»¶")
            
            # æ„å»ºå®Œæ•´è·¯å¾„è¿›è¡ŒåŒ¹é…
            # Paratranz æ–‡ä»¶çš„ name å­—æ®µåŒ…å«å®Œæ•´è·¯å¾„ï¼Œå¦‚ "Entities/Clothing.json"
            expected_full_path = (remote_path.strip('/') + '/' + filename).lstrip('/')
            
            for f in files:
                file_name = f.get('name', '')
                # å…ˆå°è¯•å®Œæ•´è·¯å¾„åŒ¹é…
                if file_name == expected_full_path:
                    log(f"æ‰¾åˆ°æ–‡ä»¶ (å®Œæ•´è·¯å¾„): {expected_full_path} (ID: {f.get('id')})")
                    return f.get('id')
            
            # å›é€€ï¼šä»…æŒ‰æ–‡ä»¶ååŒ¹é…ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            for f in files:
                file_name = f.get('name', '')
                if file_name == filename or file_name.endswith('/' + filename):
                    log(f"æ‰¾åˆ°æ–‡ä»¶ (æ–‡ä»¶ååŒ¹é…): {file_name} (ID: {f.get('id')})")
                    return f.get('id')
            
            log(f"æœªæ‰¾åˆ°æ–‡ä»¶: {expected_full_path}", "WARNING")
            return None
        except Exception as e:
            log(f"è·å–æ–‡ä»¶åˆ—è¡¨é”™è¯¯: {e}", "ERROR")
            return None

    def upload_file(self, file_path: str, remote_path: str = "/") -> bool:
        """ä¸Šä¼ æ–‡ä»¶åˆ° Paratranzï¼ˆåˆ›å»ºæˆ–æ›´æ–°ï¼‰"""
        if not os.path.exists(file_path):
            log(f"âŒ æœªæ‰¾åˆ°æœ¬åœ°æ–‡ä»¶: {file_path}", "ERROR")
            return False

        filename = os.path.basename(file_path)
        log(f"å‡†å¤‡ä¸Šä¼ æ–‡ä»¶: {filename} -> {remote_path}")
        
        # ä¼ é€’ remote_path è¿›è¡Œç²¾ç¡®åŒ¹é…
        file_id = self.get_file_id(filename, remote_path)

        try:
            with open(file_path, 'rb') as f:
                files = {'file': (filename, f, 'application/json')}
                
                if file_id:
                    log(f"æ›´æ–°ç°æœ‰æ–‡ä»¶: {filename} (ID: {file_id})")
                    url = f"{self.BASE_URL}/projects/{self.project_id}/files/{file_id}"
                    response = self._request_with_retry("POST", url, files=files)
                else:
                    log(f"åˆ›å»ºæ–°æ–‡ä»¶: {filename} åœ¨ {remote_path}")
                    url = f"{self.BASE_URL}/projects/{self.project_id}/files"
                    data = {'path': remote_path}
                    response = self._request_with_retry("POST", url, files=files, data=data)

            if response.status_code in [200, 201]:
                log("âœ… ä¸Šä¼ æˆåŠŸ")
                return True
            else:
                try:
                    error_msg = response.json().get('message', response.text)
                except:
                    error_msg = response.text
                log(f"âŒ ä¸Šä¼ å¤±è´¥: {error_msg}", "ERROR")
                return False
        except Exception as e:
            log(f"âŒ ä¸Šä¼ å¼‚å¸¸: {e}", "ERROR")
            return False

    def upload_folder(self, local_dir: str) -> Dict[str, int]:
        """
        æ‰¹é‡ä¸Šä¼ ç›®å½•ä¸‹æ‰€æœ‰ JSON æ–‡ä»¶åˆ° Paratranzï¼Œä¿æŒè·¯å¾„ç»“æ„ã€‚
        
        æ–‡ä»¶åæ ¼å¼çº¦å®šï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. å®Œæ•´è·¯å¾„æ ¼å¼ï¼šEntities/Clothing.json -> ä¸Šä¼ åˆ° /Entities/Clothing/ è·¯å¾„
        2. ä¸‹åˆ’çº¿æ ¼å¼ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰ï¼šEntities_Clothing.json -> ä¸Šä¼ åˆ° /Entities/Clothing/ è·¯å¾„
        
        è¿”å›ç»Ÿè®¡ä¿¡æ¯ã€‚
        """
        stats = {"uploaded": 0, "failed": 0, "skipped": 0}
        
        if not os.path.isdir(local_dir):
            log(f"âŒ ç›®å½•ä¸å­˜åœ¨: {local_dir}", "ERROR")
            return stats
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶ï¼ˆæ”¯æŒå­ç›®å½•ç»“æ„ï¼‰
        json_files = []
        for root, dirs, files in os.walk(local_dir):
            for f in files:
                if f.endswith('.json'):
                    # ä¿å­˜ç›¸å¯¹è·¯å¾„
                    rel_path = os.path.relpath(os.path.join(root, f), local_dir)
                    json_files.append(rel_path)
        
        if not json_files:
            log(f"âš ï¸ ç›®å½•ä¸­æ²¡æœ‰ JSON æ–‡ä»¶: {local_dir}", "WARNING")
            return stats
        
        log(f"ğŸ“¤ æ‰¹é‡ä¸Šä¼  {len(json_files)} ä¸ªæ–‡ä»¶åˆ° Paratranz...")
        
        for i, rel_path in enumerate(json_files):
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if should_stop():
                log(f"â¹ ä¸Šä¼ å·²åœæ­¢ï¼Œå·²å®Œæˆ {stats['uploaded']} ä¸ª")
                stats["skipped"] = len(json_files) - i
                break
            
            file_path = os.path.join(local_dir, rel_path)
            try:
                file_size = os.path.getsize(file_path)
            except:
                file_size = 0
            
            # ä»ç›¸å¯¹è·¯å¾„æ¨æ–­è¿œç¨‹è·¯å¾„
            # ä¾‹å¦‚ï¼šEntities/Clothing.json -> /Entities/Clothing/
            # æˆ–è€…ï¼šEntities/Clothing/Hats.json -> /Entities/Clothing/Hats/
            remote_dir = os.path.dirname(rel_path).replace('\\', '/')
            base_name = os.path.splitext(os.path.basename(rel_path))[0]
            
            if remote_dir:
                # æœ‰å­ç›®å½•ï¼šEntities/Clothing/Hats.json -> /Entities/Clothing/Hats/
                remote_path = '/' + remote_dir + '/' + base_name + '/'
            else:
                # æ ¹ç›®å½•ä¸‹ï¼šEntities.json -> /Entities/ æˆ– Entities/Clothing.json -> /Entities/Clothing/
                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼ˆå®Œæ•´è·¯å¾„æ ¼å¼ï¼‰
                if '/' in base_name:
                    remote_path = '/' + base_name + '/'
                else:
                    remote_path = '/' + base_name + '/'
            
            # æ¸…ç†å¤šä½™çš„æ–œæ 
            remote_path = '/' + remote_path.strip('/').replace('//', '/') + '/'
            if remote_path == '//':
                remote_path = '/'
            
            log(f"[{i+1}/{len(json_files)}] ä¸Šä¼ : {rel_path} ({file_size/1024:.1f}KB) -> {remote_path}")
            report_progress(i + 1, len(json_files), f"ä¸Šä¼ : {os.path.basename(rel_path)}")
            
            if self.upload_file(file_path, remote_path):
                stats["uploaded"] += 1
            else:
                stats["failed"] += 1
            
            # é¿å… API é€Ÿç‡é™åˆ¶
            time.sleep(0.5)
        
        log(f"âœ… æ‰¹é‡ä¸Šä¼ å®Œæˆã€‚æˆåŠŸ: {stats['uploaded']}ï¼Œå¤±è´¥: {stats['failed']}ï¼Œè·³è¿‡: {stats['skipped']}")
        return stats

    def upload_translation(self, file_path: str, remote_path: str = "/", force: bool = False) -> bool:
        """
        ä¸Šä¼ è¯‘æ–‡åˆ° Paratranzï¼ˆä»…æ›´æ–°ç¿»è¯‘ï¼Œä¸æ”¹åŸæ–‡ï¼‰ã€‚
        
        ä½¿ç”¨ API: POST /projects/{projectId}/files/{fileId}/translation
        
        å‚æ•°:
            file_path: æœ¬åœ° JSON æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å« translation å­—æ®µï¼‰
            remote_path: è¿œç¨‹è·¯å¾„ï¼ˆç”¨äºåŒ¹é…å¯¹åº”çš„åŸæ–‡æ–‡ä»¶ï¼‰
            force: æ˜¯å¦å¼ºåˆ¶è¦†ç›–å·²äººå·¥ç¼–è¾‘çš„è¯æ¡ï¼ˆé»˜è®¤ Falseï¼‰
        """
        if not os.path.exists(file_path):
            log(f"âŒ æœªæ‰¾åˆ°æœ¬åœ°æ–‡ä»¶: {file_path}", "ERROR")
            return False

        filename = os.path.basename(file_path)
        log(f"ğŸ“ å‡†å¤‡ä¸Šä¼ è¯‘æ–‡: {filename} -> {remote_path}")
        
        # æŸ¥æ‰¾å¯¹åº”çš„åŸæ–‡æ–‡ä»¶ ID
        file_id = self.get_file_id(filename, remote_path)
        if not file_id:
            log(f"âŒ æœªæ‰¾åˆ°å¯¹åº”çš„åŸæ–‡æ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ åŸæ–‡: {filename}", "ERROR")
            return False

        try:
            url = f"{self.BASE_URL}/projects/{self.project_id}/files/{file_id}/translation"
            
            with open(file_path, 'rb') as f:
                files = {'file': (filename, f, 'application/json')}
                data = {'force': 'true' if force else 'false'}
                response = self._request_with_retry("POST", url, files=files, data=data)

            if response.status_code in [200, 201]:
                log(f"âœ… è¯‘æ–‡ä¸Šä¼ æˆåŠŸ: {filename}")
                return True
            else:
                try:
                    error_msg = response.json().get('message', response.text)
                except:
                    error_msg = response.text
                log(f"âŒ è¯‘æ–‡ä¸Šä¼ å¤±è´¥: {error_msg}", "ERROR")
                return False
        except Exception as e:
            log(f"âŒ è¯‘æ–‡ä¸Šä¼ å¼‚å¸¸: {e}", "ERROR")
            return False

    def upload_translation_folder(self, local_dir: str, force: bool = False) -> Dict[str, int]:
        """
        æ‰¹é‡ä¸Šä¼ ç›®å½•ä¸‹æ‰€æœ‰ JSON æ–‡ä»¶çš„è¯‘æ–‡åˆ° Paratranzã€‚
        
        å‚æ•°:
            local_dir: æœ¬åœ°ç›®å½•ï¼ˆåŒ…å« JSON æ–‡ä»¶ï¼‰
            force: æ˜¯å¦å¼ºåˆ¶è¦†ç›–å·²äººå·¥ç¼–è¾‘çš„è¯æ¡
        
        è¿”å›ç»Ÿè®¡ä¿¡æ¯ã€‚
        """
        stats = {"uploaded": 0, "failed": 0, "skipped": 0}
        
        if not os.path.isdir(local_dir):
            log(f"âŒ ç›®å½•ä¸å­˜åœ¨: {local_dir}", "ERROR")
            return stats
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶
        json_files = []
        for root, dirs, files in os.walk(local_dir):
            for f in files:
                if f.endswith('.json'):
                    rel_path = os.path.relpath(os.path.join(root, f), local_dir)
                    json_files.append(rel_path)
        
        if not json_files:
            log(f"âš ï¸ ç›®å½•ä¸­æ²¡æœ‰ JSON æ–‡ä»¶: {local_dir}", "WARNING")
            return stats
        
        log(f"ğŸ“ æ‰¹é‡ä¸Šä¼ è¯‘æ–‡ {len(json_files)} ä¸ªæ–‡ä»¶åˆ° Paratranz...")
        if force:
            log("âš ï¸ å¼ºåˆ¶æ¨¡å¼å·²å¯ç”¨ï¼Œå°†è¦†ç›–å·²äººå·¥ç¼–è¾‘çš„è¯æ¡", "WARNING")
        
        for i, rel_path in enumerate(json_files):
            if should_stop():
                log(f"â¹ ä¸Šä¼ å·²åœæ­¢ï¼Œå·²å®Œæˆ {stats['uploaded']} ä¸ª")
                stats["skipped"] = len(json_files) - i
                break
            
            file_path = os.path.join(local_dir, rel_path)
            
            # æ¨æ–­è¿œç¨‹è·¯å¾„ï¼ˆä¸ upload_folder é€»è¾‘ä¸€è‡´ï¼‰
            remote_dir = os.path.dirname(rel_path).replace('\\', '/')
            base_name = os.path.splitext(os.path.basename(rel_path))[0]
            
            if remote_dir:
                remote_path = '/' + remote_dir + '/' + base_name + '/'
            else:
                remote_path = '/' + base_name + '/'
            
            remote_path = '/' + remote_path.strip('/').replace('//', '/') + '/'
            if remote_path == '//':
                remote_path = '/'
            
            log(f"[{i+1}/{len(json_files)}] è¯‘æ–‡: {rel_path} -> {remote_path}")
            report_progress(i + 1, len(json_files), f"è¯‘æ–‡: {os.path.basename(rel_path)}")
            
            if self.upload_translation(file_path, remote_path, force):
                stats["uploaded"] += 1
            else:
                stats["failed"] += 1
            
            time.sleep(0.5)
        
        log(f"âœ… è¯‘æ–‡æ‰¹é‡ä¸Šä¼ å®Œæˆã€‚æˆåŠŸ: {stats['uploaded']}ï¼Œå¤±è´¥: {stats['failed']}ï¼Œè·³è¿‡: {stats['skipped']}")
        return stats

    def trigger_export(self) -> bool:
        """è§¦å‘é¡¹ç›®å¯¼å‡ºï¼ˆç”Ÿæˆå‹ç¼©åŒ…ï¼‰"""
        log("è§¦å‘é¡¹ç›®å¯¼å‡º...")
        url = f"{self.BASE_URL}/projects/{self.project_id}/artifacts"
        try:
            response = self._request_with_retry("POST", url)
            if response.status_code in [200, 201]:
                log("âœ… å¯¼å‡ºä»»åŠ¡å·²è§¦å‘")
                return True
            elif response.status_code == 403:
                log("âš ï¸ æ²¡æœ‰è§¦å‘å¯¼å‡ºçš„æƒé™ï¼ˆä»…ç®¡ç†å‘˜å¯ç”¨ï¼‰ï¼Œå°†å°è¯•ä¸‹è½½ç°æœ‰å¯¼å‡º", "WARNING")
                return True  # ç»§ç»­å°è¯•ä¸‹è½½
            else:
                try:
                    error_msg = response.json().get('message', response.text)
                except:
                    error_msg = response.text
                log(f"è§¦å‘å¯¼å‡ºå¤±è´¥: {error_msg}", "WARNING")
                return True  # ç»§ç»­å°è¯•ä¸‹è½½ç°æœ‰å¯¼å‡º
        except Exception as e:
            log(f"è§¦å‘å¯¼å‡ºå¼‚å¸¸: {e}", "WARNING")
            return True  # ç»§ç»­å°è¯•ä¸‹è½½

    def download_artifacts(self, save_path: str) -> bool:
        """
        ä¸‹è½½é¡¹ç›®å¯¼å‡ºçš„å‹ç¼©åŒ…ï¼ˆåŒ…å«æ‰€æœ‰ç¿»è¯‘ï¼‰
        æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šGET /projects/{projectId}/artifacts/download
        """
        log("æ­£åœ¨ä¸‹è½½ç¿»è¯‘å‹ç¼©åŒ…...")
        
        # å…ˆå°è¯•è§¦å‘å¯¼å‡ºï¼ˆå¯èƒ½éœ€è¦ç®¡ç†å‘˜æƒé™ï¼‰
        self.trigger_export()
        
        # ç­‰å¾…ä¸€å°ä¼šè®©æœåŠ¡å™¨å‡†å¤‡
        time.sleep(1)
        
        url = f"{self.BASE_URL}/projects/{self.project_id}/artifacts/download"
        
        try:
            # ä½¿ç”¨ allow_redirects=True è·Ÿéšé‡å®šå‘
            log(f"è¯·æ±‚ä¸‹è½½: {url}")
            response = requests.get(url, headers=self.headers, timeout=60, allow_redirects=True, stream=True)
            
            log(f"ä¸‹è½½å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                # ä¿å­˜ä¸º zip æ–‡ä»¶
                zip_path = save_path.replace('.json', '.zip') if save_path.endswith('.json') else save_path + '.zip'
                with open(zip_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                log(f"âœ… å·²ä¸‹è½½å‹ç¼©åŒ…åˆ°: {zip_path}")
                
                # è§£å‹å¹¶æå–ç¿»è¯‘
                return self._extract_translations_from_zip(zip_path, save_path)
                
            elif response.status_code == 302:
                # æ‰‹åŠ¨å¤„ç†é‡å®šå‘
                redirect_url = response.headers.get('Location')
                if redirect_url:
                    log(f"é‡å®šå‘åˆ°: {redirect_url}")
                    response = requests.get(redirect_url, timeout=60, stream=True)
                    if response.status_code == 200:
                        zip_path = save_path.replace('.json', '.zip') if save_path.endswith('.json') else save_path + '.zip'
                        with open(zip_path, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                f.write(chunk)
                        log(f"âœ… å·²ä¸‹è½½å‹ç¼©åŒ…åˆ°: {zip_path}")
                        return self._extract_translations_from_zip(zip_path, save_path)
            else:
                try:
                    error_msg = response.json().get('message', response.text[:200])
                except:
                    error_msg = response.text[:200] if response.text else "æœªçŸ¥é”™è¯¯"
                log(f"âŒ ä¸‹è½½å¤±è´¥ ({response.status_code}): {error_msg}", "ERROR")
                return False
                
        except Exception as e:
            log(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}", "ERROR")
            return False

    def _extract_translations_from_zip(self, zip_path: str, output_path: str) -> bool:
        """ä»ä¸‹è½½çš„å‹ç¼©åŒ…ä¸­æå–ç¿»è¯‘æ•°æ®"""
        import zipfile
        
        try:
            log(f"æ­£åœ¨è§£å‹: {zip_path}")
            
            with zipfile.ZipFile(zip_path, 'r') as zf:
                # åˆ—å‡ºå‹ç¼©åŒ…å†…å®¹
                file_list = zf.namelist()
                log(f"å‹ç¼©åŒ…å†…åŒ…å« {len(file_list)} ä¸ªæ–‡ä»¶")
                
                # æŸ¥æ‰¾ JSON æ–‡ä»¶
                json_files = [f for f in file_list if f.endswith('.json')]
                
                if json_files:
                    # æå–ç¬¬ä¸€ä¸ª JSON æ–‡ä»¶
                    target_file = json_files[0]
                    log(f"æå–æ–‡ä»¶: {target_file}")
                    
                    with zf.open(target_file) as source:
                        content = source.read()
                        with open(output_path, 'wb') as target:
                            target.write(content)
                    
                    log(f"âœ… å·²ä¿å­˜ç¿»è¯‘åˆ°: {output_path}")
                    return True
                else:
                    # å¦‚æœæ²¡æœ‰ JSONï¼Œè§£å‹æ‰€æœ‰æ–‡ä»¶åˆ°å½“å‰ç›®å½•
                    extract_dir = os.path.dirname(output_path) or '.'
                    zf.extractall(extract_dir)
                    log(f"âœ… å·²è§£å‹æ‰€æœ‰æ–‡ä»¶åˆ°: {extract_dir}")
                    return True
                    
        except zipfile.BadZipFile:
            log("âŒ ä¸‹è½½çš„æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„å‹ç¼©åŒ…", "ERROR")
            return False
        except Exception as e:
            log(f"âŒ è§£å‹å¤±è´¥: {e}", "ERROR")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶ zip æ–‡ä»¶
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
            except:
                pass

    def download_file(self, save_path: str, remote_filename: str = "") -> bool:
        """
        ä¸‹è½½ç¿»è¯‘æ–‡ä»¶
        ä½¿ç”¨ artifacts/download ç«¯ç‚¹ä¸‹è½½é¡¹ç›®å¯¼å‡º
        """
        return self.download_artifacts(save_path)

# ==================== æå–é€»è¾‘ (Extraction Logic) ====================

# å“ˆå¸Œç¼“å­˜æ–‡ä»¶å
HASH_CACHE_FILE = ".extract_cache.json"

def compute_file_hash(file_path: str) -> str:
    """è®¡ç®—æ–‡ä»¶çš„ MD5 å“ˆå¸Œå€¼"""
    hasher = hashlib.md5()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            hasher.update(chunk)
    return hasher.hexdigest()

def load_hash_cache(cache_file: str) -> Dict[str, str]:
    """åŠ è½½å“ˆå¸Œç¼“å­˜"""
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}

def save_hash_cache(cache_file: str, cache: Dict[str, str]):
    """ä¿å­˜å“ˆå¸Œç¼“å­˜"""
    with open(cache_file, 'w', encoding='utf-8') as f:
        json.dump(cache, f, indent=2)

def extract_strings(scan_dir: str, output_file: str, fields: List[str] = None, 
                    incremental: bool = False, filter_ftl: bool = True) -> Dict[str, int]:
    """
    æ‰«æ scan_dir ä¸­çš„ YAML æ–‡ä»¶å¹¶æå–å­—ç¬¦ä¸²åˆ° output_fileã€‚
    
    å‚æ•°:
        scan_dir: æ‰«æç›®å½•
        output_file: è¾“å‡º JSON æ–‡ä»¶
        fields: è¦æå–çš„å­—æ®µåˆ—è¡¨
        incremental: æ˜¯å¦ä½¿ç”¨å¢é‡æ¨¡å¼ï¼ˆè·³è¿‡æœªä¿®æ”¹çš„æ–‡ä»¶ï¼‰
        filter_ftl: æ˜¯å¦è¿‡æ»¤ FTL æœ¬åœ°åŒ–é”®ï¼ˆé»˜è®¤å¼€å¯ï¼‰
    
    è¿”å›ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    if fields is None:
        fields = DEFAULT_TRANSLATABLE_FIELDS
        
    yaml_processor = YAMLProcessor()
    extracted_data: List[Dict] = []
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "files_scanned": 0,
        "files_with_text": 0,
        "files_skipped": 0,  # å¢é‡æ¨¡å¼ä¸‹è·³è¿‡çš„æ–‡ä»¶æ•°
        "ftl_skipped": 0,    # FTL é”®è¿‡æ»¤è·³è¿‡çš„æ¡ç›®æ•°
        "total_strings": 0,
        "by_field": {f: 0 for f in fields}
    }
    
    # å¢é‡æ¨¡å¼ï¼šåŠ è½½å“ˆå¸Œç¼“å­˜å’Œå·²æœ‰æå–ç»“æœ
    cache_file = os.path.join(os.path.dirname(output_file) or '.', HASH_CACHE_FILE)
    hash_cache: Dict[str, str] = {}
    existing_data: Dict[str, Dict] = {}  # key -> entry
    
    if incremental:
        log("ğŸ“Š å¢é‡æ¨¡å¼å·²å¯ç”¨ï¼Œå°†è·³è¿‡æœªä¿®æ”¹çš„æ–‡ä»¶")
        hash_cache = load_hash_cache(cache_file)
        
        # åŠ è½½å·²æœ‰çš„æå–ç»“æœ
        if os.path.exists(output_file):
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    for entry in json.load(f):
                        existing_data[entry.get('key', '')] = entry
                log(f"å·²åŠ è½½ {len(existing_data)} æ¡å·²æœ‰æå–è®°å½•")
            except:
                pass
    
    new_hash_cache: Dict[str, str] = {}
    
    # æ”¶é›†æ‰€æœ‰ YAML æ–‡ä»¶
    yaml_files = []
    for root, dirs, files in os.walk(scan_dir):
        for file in files:
            if file.endswith('.yml') or file.endswith('.yaml'):
                yaml_files.append(os.path.join(root, file))
    
    total_files = len(yaml_files)
    log(f"æ­£åœ¨æ‰«æç›®å½•: {scan_dir} (å…± {total_files} ä¸ªæ–‡ä»¶)")
    
    for i, file_path in enumerate(yaml_files):
        rel_path = os.path.relpath(file_path, scan_dir)
        stats["files_scanned"] += 1
        report_progress(i + 1, total_files, f"æ‰«æ: {rel_path}")
        
        # å¢é‡æ¨¡å¼ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–
        if incremental:
            current_hash = compute_file_hash(file_path)
            new_hash_cache[rel_path] = current_hash
            
            if rel_path in hash_cache and hash_cache[rel_path] == current_hash:
                # æ–‡ä»¶æœªä¿®æ”¹ï¼Œè·³è¿‡æ‰«æï¼Œä½†ä¿ç•™å·²æœ‰æ•°æ®
                stats["files_skipped"] += 1
                continue
        
        try:
            data = yaml_processor.load(file_path)
            if not data:
                continue
            
            count_before = len(extracted_data)
            
            if isinstance(data, list):
                for node in data:
                    process_node_extract(node, extracted_data, rel_path, fields, stats, filter_ftl)
            elif isinstance(data, dict):
                process_node_extract(data, extracted_data, rel_path, fields, stats, filter_ftl)
            
            if len(extracted_data) > count_before:
                stats["files_with_text"] += 1
                 
        except Exception as e:
            log(f"è§£ææ–‡ä»¶é”™è¯¯ {file_path}: {e}", "WARNING")

    # å¢é‡æ¨¡å¼ï¼šåˆå¹¶å·²æœ‰æ•°æ®å’Œæ–°æ•°æ®
    if incremental and existing_data:
        # æ„å»ºæ–°æ•°æ®çš„ key é›†åˆ
        new_keys = {entry['key'] for entry in extracted_data}
        
        # ä¿ç•™æœªè¢«é‡æ–°æ‰«æçš„æ–‡ä»¶ä¸­çš„æ•°æ®
        for key, entry in existing_data.items():
            if key not in new_keys:
                # æ£€æŸ¥è¯¥æ¡ç›®å¯¹åº”çš„æ–‡ä»¶æ˜¯å¦è¢«è·³è¿‡ï¼ˆä»ç„¶å­˜åœ¨ï¼‰
                context = entry.get('context', '')
                # ä» context ä¸­æå–æ–‡ä»¶è·¯å¾„
                if 'æ–‡ä»¶:' in context:
                    file_line = context.split('\n')[0]
                    file_path = file_line.replace('æ–‡ä»¶:', '').strip()
                    if file_path in new_hash_cache:
                        extracted_data.append(entry)
        
        log(f"å¢é‡åˆå¹¶åå…± {len(extracted_data)} æ¡è®°å½•")

    stats["total_strings"] = len(extracted_data)
    
    log(f"æå–å®Œæˆã€‚æ‰«æ {stats['files_scanned']} ä¸ªæ–‡ä»¶ï¼Œ"
        f"è·³è¿‡ {stats['files_skipped']} ä¸ªï¼ˆæœªä¿®æ”¹ï¼‰ï¼Œ"
        f"å…¶ä¸­ {stats['files_with_text']} ä¸ªåŒ…å«æ–‡æœ¬ï¼Œ"
        f"å…± {stats['total_strings']} æ¡å­—ç¬¦ä¸²ã€‚")
    
    if stats.get("translated", 0) > 0:
        log(f"  âœ… å·²æ ‡è®° {stats['translated']} æ¡ä¸ºå·²ç¿»è¯‘çŠ¶æ€ (stage: 1)")
    
    if stats.get("ftl_skipped", 0) > 0:
        log(f"  âš ï¸ å·²è¿‡æ»¤ {stats['ftl_skipped']} æ¡ FTL æœ¬åœ°åŒ–é”®")
    
    # è¾“å‡ºå­—æ®µç»Ÿè®¡
    for field, count in stats["by_field"].items():
        if count > 0:
            log(f"  - {field}: {count} æ¡")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(extracted_data, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜æ–°çš„å“ˆå¸Œç¼“å­˜
    if incremental:
        save_hash_cache(cache_file, new_hash_cache)
        log(f"å·²æ›´æ–°æ–‡ä»¶å“ˆå¸Œç¼“å­˜: {cache_file}")
    
    log(f"å·²ä¿å­˜åˆ° {output_file}")
    return stats

def process_node_extract(node: Dict, extracted_data: List, rel_path: str, 
                         fields: List[str], stats: Dict, filter_ftl: bool = True):
    """
    æå–å•ä¸ªèŠ‚ç‚¹ä¸­çš„æ–‡æœ¬ã€‚
    
    å‚æ•°:
        filter_ftl: æ˜¯å¦è¿‡æ»¤ FTL æœ¬åœ°åŒ–é”®ï¼ˆé»˜è®¤å¼€å¯ï¼‰
    """
    if not isinstance(node, dict):
        return
        
    entity_type = node.get('type')
    entity_id = node.get('id')
    parent = node.get('parent')
    
    if entity_type == 'entity' or 'id' in node:
        if entity_id:
            key_prefix = entity_id
        elif parent:
            p_str = parent[0] if isinstance(parent, list) and parent else str(parent)
            key_prefix = f"Parent_{p_str}"
            if node.get('suffix'):
                key_prefix += f"_{node.get('suffix')}"
        else:
            return 

        for field in fields:
            if field in node and isinstance(node[field], str):
                original_text = node[field]
                if not original_text.strip():
                    continue
                
                # FTL é”®è¿‡æ»¤ï¼šè·³è¿‡å½¢å¦‚ "loadout-group-weapon" çš„æœ¬åœ°åŒ–å¼•ç”¨
                if filter_ftl and is_ftl_key(original_text):
                    stats["ftl_skipped"] = stats.get("ftl_skipped", 0) + 1
                    continue
                
                key = f"{key_prefix}.{field}"
                
                context = f"æ–‡ä»¶: {rel_path}\n"
                if entity_id:
                    context += f"ID: {entity_id}\n"
                if parent:
                    context += f"Parent: {parent}\n"
                
                # æ„å»ºè¯æ¡æ•°æ®
                entry = {
                    "key": key,
                    "original": original_text,
                    "context": context
                }
                
                # å¦‚æœåŒ…å«ä¸­æ–‡ï¼Œæ·»åŠ ç¿»è¯‘çŠ¶æ€ (stage: 1 = å·²ç¿»è¯‘)
                if contains_chinese(original_text):
                    entry["translation"] = original_text
                    entry["stage"] = 1
                    stats["translated"] = stats.get("translated", 0) + 1
                
                extracted_data.append(entry)
                
                stats["by_field"][field] = stats["by_field"].get(field, 0) + 1

# ==================== æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æå– (Folder-Based Extraction) ====================

from collections import defaultdict
import glob

def extract_strings_by_folder(scan_dir: str, output_dir: str, fields: List[str] = None,
                               filter_ftl: bool = True) -> Dict[str, int]:
    """
    æŒ‰æ–‡ä»¶å¤¹ç»“æ„æå–ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹ç”Ÿæˆä¸€ä¸ª JSON æ–‡ä»¶ï¼Œä¿ç•™å®Œæ•´ç›®å½•ç»“æ„ã€‚
    
    å‚æ•°:
        scan_dir: æ‰«æç›®å½•
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå­˜æ”¾å¤šä¸ª JSON æ–‡ä»¶ï¼‰
        fields: è¦æå–çš„å­—æ®µåˆ—è¡¨
        filter_ftl: æ˜¯å¦è¿‡æ»¤ FTL æœ¬åœ°åŒ–é”®
    
    è¿”å›ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    if fields is None:
        fields = DEFAULT_TRANSLATABLE_FIELDS
    
    yaml_processor = YAMLProcessor()
    
    # æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„çš„æ•°æ®
    folder_data: Dict[str, List[Dict]] = defaultdict(list)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "files_scanned": 0,
        "files_with_text": 0,
        "ftl_skipped": 0,
        "total_strings": 0,
        "folder_count": 0,
        "by_field": {f: 0 for f in fields}
    }
    
    # æ”¶é›†æ‰€æœ‰ YAML æ–‡ä»¶
    yaml_files = []
    for root, dirs, files in os.walk(scan_dir):
        for file in files:
            if file.endswith('.yml') or file.endswith('.yaml'):
                yaml_files.append(os.path.join(root, file))
    
    total_files = len(yaml_files)
    log(f"ğŸ“‚ æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æ¨¡å¼ï¼šæ‰«æ {scan_dir} (å…± {total_files} ä¸ªæ–‡ä»¶)")
    
    for i, file_path in enumerate(yaml_files):
        rel_path = os.path.relpath(file_path, scan_dir)
        stats["files_scanned"] += 1
        report_progress(i + 1, total_files, f"æ‰«æ: {rel_path}")
        
        # è®¡ç®—åˆ†ç»„é”®ï¼ˆä½¿ç”¨å®Œæ•´æ–‡ä»¶å¤¹è·¯å¾„ï¼Œç”¨ / åˆ†éš”ï¼‰
        folder = os.path.dirname(rel_path).replace('\\', '/')
        
        # ä½¿ç”¨å®Œæ•´è·¯å¾„ä½œä¸ºåˆ†ç»„é”®ï¼Œç©ºè·¯å¾„ä½¿ç”¨ "root"
        group_key = folder if folder else "root"
        
        try:
            file_size = os.path.getsize(file_path)
            data = yaml_processor.load(file_path)
            if not data:
                continue
            
            # ä¸´æ—¶å­˜å‚¨æœ¬æ–‡ä»¶æå–çš„æ•°æ®
            file_entries: List[Dict] = []
            file_stats = {"ftl_skipped": 0, "by_field": {f: 0 for f in fields}}
            
            if isinstance(data, list):
                for node in data:
                    process_node_extract(node, file_entries, rel_path, fields, file_stats, filter_ftl)
            elif isinstance(data, dict):
                process_node_extract(data, file_entries, rel_path, fields, file_stats, filter_ftl)
            
            if file_entries:
                folder_data[group_key].extend(file_entries)
                stats["files_with_text"] += 1
                log(f"  + [{len(file_entries)}æ¡] {rel_path} ({file_size/1024:.1f}KB)", "DEBUG")
            
            # ç´¯è®¡ç»Ÿè®¡
            stats["ftl_skipped"] += file_stats.get("ftl_skipped", 0)
            for field, count in file_stats["by_field"].items():
                stats["by_field"][field] = stats["by_field"].get(field, 0) + count
                
        except Exception as e:
            log(f"è§£ææ–‡ä»¶é”™è¯¯ {file_path}: {e}", "WARNING")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¸ºæ¯ä¸ªåˆ†ç»„ç”Ÿæˆ JSON æ–‡ä»¶ï¼ˆä¿æŒç›®å½•ç»“æ„ï¼‰
    for group_name, entries in folder_data.items():
        if not entries:
            continue
        
        # group_name æ ¼å¼å¦‚ "Entities/Clothing" æˆ– "root"
        if group_name == "root":
            output_file = os.path.join(output_dir, "root.json")
        else:
            # åˆ›å»ºå­ç›®å½•ç»“æ„
            # Entities/Clothing -> output_dir/Entities/Clothing.json
            parent_dir = os.path.dirname(group_name)
            base_name = os.path.basename(group_name)
            
            if parent_dir:
                full_parent = os.path.join(output_dir, parent_dir)
                os.makedirs(full_parent, exist_ok=True)
                output_file = os.path.join(full_parent, f"{base_name}.json")
            else:
                output_file = os.path.join(output_dir, f"{base_name}.json")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(entries, f, indent=2, ensure_ascii=False)
        
        stats["total_strings"] += len(entries)
        stats["folder_count"] += 1
        log(f"  ğŸ“„ {group_name}.json: {len(entries)} æ¡")
    
    log(f"âœ… æå–å®Œæˆã€‚æ‰«æ {stats['files_scanned']} ä¸ªæ–‡ä»¶ï¼Œ"
        f"ç”Ÿæˆ {stats['folder_count']} ä¸ª JSON æ–‡ä»¶ï¼Œ"
        f"å…± {stats['total_strings']} æ¡å­—ç¬¦ä¸²ã€‚")
    
    if stats.get("ftl_skipped", 0) > 0:
        log(f"  âš ï¸ å·²è¿‡æ»¤ {stats['ftl_skipped']} æ¡ FTL æœ¬åœ°åŒ–é”®")
    
    return stats

# ==================== åˆå¹¶é€»è¾‘ (Merge Logic) ====================

def merge_translations(repo_root: str, translation_file: str, output_dir: str, 
                       fields: List[str] = None) -> Dict[str, int]:
    """
    å°† JSON ä¸­çš„ç¿»è¯‘åˆå¹¶åˆ° repo_root ä¸‹çš„ YAML æ–‡ä»¶ä¸­ã€‚
    è¿”å›ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    if fields is None:
        fields = DEFAULT_TRANSLATABLE_FIELDS
        
    yaml_processor = YAMLProcessor()
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "files_modified": 0,
        "strings_applied": 0,
        "strings_skipped": 0,
        "translations_unused": 0
    }
    
    if not os.path.exists(translation_file):
        log(f"æœªæ‰¾åˆ°ç¿»è¯‘æ–‡ä»¶: {translation_file}", "ERROR")
        return stats

    with open(translation_file, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
        
    translation_map: Dict[str, str] = {}
    if isinstance(raw_data, list):
        for item in raw_data:
            start_key = item.get('key')
            translation = item.get('translation', '')
            if start_key and translation:
                translation_map[start_key] = translation
    elif isinstance(raw_data, dict):
        translation_map = raw_data
    
    used_keys = set()
    log(f"å·²åŠ è½½ {len(translation_map)} æ¡ç¿»è¯‘ã€‚")
    
    # æ”¶é›†æ‰€æœ‰ YAML æ–‡ä»¶
    yaml_files = []
    for root, dirs, files in os.walk(repo_root):
        for file in files:
            if file.endswith('.yml') or file.endswith('.yaml'):
                yaml_files.append(os.path.join(root, file))
    
    total_files = len(yaml_files)
    log(f"è¯»å–ç›®å½•: {repo_root} (å…± {total_files} ä¸ªæ–‡ä»¶)")
    log(f"å†™å…¥ç›®å½•: {output_dir}")
    
    for i, file_path in enumerate(yaml_files):
        rel_path = os.path.relpath(file_path, repo_root)
        report_progress(i + 1, total_files, f"åˆå¹¶: {rel_path}")
        
        try:
            data = yaml_processor.load(file_path)
            if not data:
                continue
            
            modified = False
            
            if isinstance(data, list):
                for node in data:
                    result = process_node_merge(node, translation_map, fields, used_keys)
                    if result["modified"]:
                        modified = True
                    stats["strings_applied"] += result["applied"]
                    stats["strings_skipped"] += result["skipped"]
            elif isinstance(data, dict):
                result = process_node_merge(data, translation_map, fields, used_keys)
                if result["modified"]:
                    modified = True
                stats["strings_applied"] += result["applied"]
                stats["strings_skipped"] += result["skipped"]
            
            if modified:
                out_path = os.path.join(output_dir, rel_path)
                os.makedirs(os.path.dirname(out_path), exist_ok=True)
                yaml_processor.dump(data, out_path)
                stats["files_modified"] += 1
                
        except Exception as e:
            log(f"å¤„ç†æ–‡ä»¶é”™è¯¯ {file_path}: {e}", "WARNING")
    
    stats["translations_unused"] = len(translation_map) - len(used_keys)
    
    log(f"åˆå¹¶å®Œæˆã€‚ä¿®æ”¹äº† {stats['files_modified']} ä¸ªæ–‡ä»¶ï¼Œ"
        f"åº”ç”¨äº† {stats['strings_applied']} æ¡ç¿»è¯‘ï¼Œ"
        f"è·³è¿‡ {stats['strings_skipped']} æ¡ï¼ˆå†…å®¹ç›¸åŒï¼‰ï¼Œ"
        f"æœªä½¿ç”¨ {stats['translations_unused']} æ¡ã€‚")
    
    return stats

def process_node_merge(node: Dict, translation_map: Dict[str, str], 
                       fields: List[str], used_keys: set) -> Dict[str, Any]:
    """åˆå¹¶å•ä¸ªèŠ‚ç‚¹ä¸­çš„ç¿»è¯‘"""
    result = {"modified": False, "applied": 0, "skipped": 0}
    
    if not isinstance(node, dict):
        return result
        
    entity_id = node.get('id')
    parent = node.get('parent')
    
    if 'id' in node or node.get('type') == 'entity':
        if entity_id:
            key_prefix = entity_id
        elif parent:
            p_str = parent[0] if isinstance(parent, list) and parent else str(parent)
            key_prefix = f"Parent_{p_str}"
            if node.get('suffix'):
                key_prefix += f"_{node.get('suffix')}"
        else:
            return result

        for field in fields:
            if field in node:
                key = f"{key_prefix}.{field}"
                if key in translation_map:
                    used_keys.add(key)
                    new_text = translation_map[key]
                    if new_text and new_text != node[field]:
                        node[field] = new_text
                        result["modified"] = True
                        result["applied"] += 1
                    else:
                        result["skipped"] += 1
                         
    return result

# ==================== ä¸€é”®å·¥ä½œæµ (One-Click Workflow) ====================

def run_full_workflow(scan_dir: str, output_json: str, translation_json: str,
                      project_id: int, token: str, output_dir: str,
                      fields: List[str] = None, by_folder: bool = False,
                      filter_ftl: bool = True, incremental: bool = False) -> bool:
    """
    æ‰§è¡Œå®Œæ•´çš„æ±‰åŒ–å·¥ä½œæµï¼šæå– â†’ ä¸Šä¼  â†’ ä¸‹è½½ â†’ åˆå¹¶
    
    å‚æ•°:
        by_folder: æ˜¯å¦æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æ¨¡å¼ï¼ˆç”Ÿæˆå¤šä¸ª JSONï¼‰
        filter_ftl: æ˜¯å¦è¿‡æ»¤ FTL é”®
    """
    log("=" * 50)
    log("å¼€å§‹æ‰§è¡Œä¸€é”®å·¥ä½œæµ")
    if by_folder:
        log("ğŸ“‚ æ¨¡å¼: æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„")
    else:
        log("ğŸ“„ æ¨¡å¼: å•æ–‡ä»¶")
    log("=" * 50)
    
    # æ­¥éª¤ 1: æå–
    log("\n[æ­¥éª¤ 1/4] æå–åŸæ–‡...")
    try:
        if by_folder:
            # åˆ†ç»„æ¨¡å¼ï¼šè¾“å‡ºåˆ°ç›®å½•
            extract_strings_by_folder(scan_dir, output_json, fields, 
                                      filter_ftl=filter_ftl)
        else:
            # å•æ–‡ä»¶æ¨¡å¼
            extract_strings(scan_dir, output_json, fields, 
                           incremental=incremental, filter_ftl=filter_ftl)
    except Exception as e:
        log(f"æå–å¤±è´¥: {e}", "ERROR")
        return False
    
    # æ­¥éª¤ 2: ä¸Šä¼ 
    log("\n[æ­¥éª¤ 2/4] ä¸Šä¼ åˆ° Paratranz...")
    try:
        client = PZClient(project_id, token)
        if not client.test_connection():
            log("API è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œç»ˆæ­¢å·¥ä½œæµ", "ERROR")
            return False
        
        if by_folder:
            # åˆ†ç»„æ¨¡å¼ï¼šæ‰¹é‡ä¸Šä¼ ç›®å½•
            result = client.upload_folder(output_json)
            if result.get("failed", 0) > result.get("uploaded", 0):
                log("æ‰¹é‡ä¸Šä¼ å¤±è´¥è¿‡å¤šï¼Œç»ˆæ­¢å·¥ä½œæµ", "ERROR")
                return False
        else:
            # å•æ–‡ä»¶æ¨¡å¼
            if not client.upload_file(output_json):
                log("ä¸Šä¼ å¤±è´¥ï¼Œç»ˆæ­¢å·¥ä½œæµ", "ERROR")
                return False
    except Exception as e:
        log(f"ä¸Šä¼ å¤±è´¥: {e}", "ERROR")
        return False
    
    # æ­¥éª¤ 3: ä¸‹è½½
    log("\n[æ­¥éª¤ 3/4] ä» Paratranz ä¸‹è½½ç¿»è¯‘...")
    try:
        if not client.download_file(translation_json, os.path.basename(output_json)):
            log("ä¸‹è½½å¤±è´¥ï¼Œç»ˆæ­¢å·¥ä½œæµ", "ERROR")
            return False
    except Exception as e:
        log(f"ä¸‹è½½å¤±è´¥: {e}", "ERROR")
        return False
    
    # æ­¥éª¤ 4: åˆå¹¶
    log("\n[æ­¥éª¤ 4/4] åˆå¹¶ç¿»è¯‘...")
    try:
        merge_translations(scan_dir, translation_json, output_dir, fields)
    except Exception as e:
        log(f"åˆå¹¶å¤±è´¥: {e}", "ERROR")
        return False
    
    log("\n" + "=" * 50)
    log("âœ… ä¸€é”®å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
    log("=" * 50)
    return True

# ==================== å›¾å½¢ç•Œé¢ (GUI) ====================

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext

class App:
    def __init__(self, root):
        self.root = root
        self.root.title("SS14 è‡ªåŠ¨åŒ–æ±‰åŒ–å·¥å…·ç®± v3.2")
        self.root.geometry("1100x800")
        self.root.minsize(1050, 700)
        
        # åŠ è½½é…ç½®
        self.config = self.load_config()
        self.is_running = False
        self.stop_requested = False

        # æ³¨å†Œ GUI æ—¥å¿—å›è°ƒ
        gui_log_handler.set_callback(self.update_gui_log)

        # è®¾ç½®ç°ä»£åŒ–æ ·å¼ä¸»é¢˜
        self._setup_styles()
        
        # è®¾ç½®çª—å£èƒŒæ™¯è‰²
        self.root.configure(bg=self.colors['bg'])
        
        # === åˆ›å»ºå¯æ»šåŠ¨çš„ä¸»å®¹å™¨ ===
        # å¤–å±‚å®¹å™¨
        outer_frame = ttk.Frame(self.root)
        outer_frame.pack(fill=tk.BOTH, expand=True)
        
        # åˆ›å»º Canvas å’Œæ»šåŠ¨æ¡
        self.canvas = tk.Canvas(outer_frame, bg=self.colors['bg'], highlightthickness=0)
        scrollbar = ttk.Scrollbar(outer_frame, orient="vertical", command=self.canvas.yview)
        
        # å¯æ»šåŠ¨çš„å†…éƒ¨ Frame
        self.scrollable_frame = ttk.Frame(self.canvas, style='Main.TFrame')
        
        # å½“å†…å®¹å˜åŒ–æ—¶æ›´æ–°æ»šåŠ¨åŒºåŸŸ
        self.scrollable_frame.bind(
            "<Configure>",
            lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        )
        
        # åœ¨ Canvas ä¸­åˆ›å»ºçª—å£
        self.canvas_window = self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        
        # å½“ Canvas å¤§å°å˜åŒ–æ—¶ï¼Œè°ƒæ•´å†…éƒ¨ Frame å®½åº¦
        self.canvas.bind("<Configure>", self._on_canvas_configure)
        
        # é…ç½®æ»šåŠ¨æ¡
        self.canvas.configure(yscrollcommand=scrollbar.set)
        
        # å¸ƒå±€
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # ç»‘å®šé¼ æ ‡æ»šè½®äº‹ä»¶
        self._bind_mousewheel()
        
        # æ„å»ºä¸»ç•Œé¢å†…å®¹
        self._build_ui()
        
        self.root.protocol("WM_DELETE_WINDOW", self.on_close)
        
        # è‡ªåŠ¨æ£€æµ‹ç›®å½•
        self.auto_detect_directory()

    def _setup_styles(self):
        """é…ç½®ç°ä»£åŒ–çš„UIæ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')
        
        # === é¢œè‰²å®šä¹‰ (Slate/Blue Theme) ===
        self.colors = {
            'primary': '#1890ff',       # ä¸»è‰² - ç§‘æŠ€è“
            'primary_hover': '#40a9ff',
            'primary_dark': '#096dd9',  # å…¼å®¹æ—§ä»£ç 
            'success': '#52c41a',       # æˆåŠŸ - é²œç»¿
            'success_hover': '#73d13d',
            'success_dark': '#389e0d',  # å…¼å®¹æ—§ä»£ç 
            'warning': '#faad14',       # è­¦å‘Š - é‡‘é»„
            'warning_hover': '#ffc53d',
            'danger': '#ff4d4f',        # å±é™© - çº¢è‰²
            'danger_hover': '#ff7875',
            'bg': '#f0f2f5',            # å…¨å±€èƒŒæ™¯ - æµ…ç°
            'card_bg': '#ffffff',       # å¡ç‰‡èƒŒæ™¯ - çº¯ç™½
            'text': '#262626',          # ä¸»æ–‡æœ¬ - æ·±é»‘
            'text_secondary': '#595959',# æ¬¡è¦æ–‡æœ¬ - ç°
            'text_muted': '#8c8c8c',    # å…¼å®¹æ—§ä»£ç  (æç¤ºæ–‡æœ¬)
            'text_hint': '#8c8c8c',     # æç¤ºæ–‡æœ¬
            'border': '#d9d9d9',        # è¾¹æ¡†
            'input_bg': '#ffffff',      # è¾“å…¥æ¡†èƒŒæ™¯
        }
        
        # === å­—ä½“å®šä¹‰ ===
        base_font = 'Microsoft YaHei UI' if sys.platform == 'win32' else 'Helvetica'
        self.fonts = {
            'h1': (base_font, 18, 'bold'),
            'h2': (base_font, 14, 'bold'),
            'body': (base_font, 10),
            'body_bold': (base_font, 10, 'bold'),
            'small': (base_font, 9),
            'mono': ('Consolas', 10),
        }
        
        # å…¼å®¹æ—§ä»£ç çš„å­—ä½“å¼•ç”¨
        self.default_font = self.fonts['body']
        self.default_font_bold = self.fonts['body_bold']
        self.title_font = self.fonts['h1']
        self.mono_font = self.fonts['mono']
        
        # === æ ·å¼é…ç½® ===
        
        # åŸºç¡€ Frame å’Œ Label
        style.configure('.', background=self.colors['bg'], foreground=self.colors['text'], font=self.fonts['body'])
        style.configure('Main.TFrame', background=self.colors['bg'])
        style.configure('Card.TFrame', background=self.colors['card_bg'], relief='flat')
        
        # Label æ ·å¼
        style.configure('TLabel', background=self.colors['bg'], foreground=self.colors['text'])
        style.configure('Card.TLabel', background=self.colors['card_bg'], foreground=self.colors['text'])
        style.configure('Title.TLabel', font=self.fonts['h1'], background=self.colors['bg'])
        style.configure('CardTitle.TLabel', font=self.fonts['h2'], background=self.colors['card_bg'], foreground=self.colors['text'])
        style.configure('Hint.TLabel', background=self.colors['card_bg'], foreground=self.colors['text_hint'], font=self.fonts['small'])
        style.configure('Card.TCheckbutton', background=self.colors['card_bg'], font=self.fonts['body'])
        
        # æŒ‰é’®é€šç”¨æ ·å¼
        style.configure('TButton', font=self.fonts['body'], padding=[15, 8], borderwidth=0, relief='flat')
        
        # ä¸»è¦æŒ‰é’® (Primary)
        style.configure('Primary.TButton', 
                        background=self.colors['primary'], 
                        foreground='white',
                        font=self.fonts['body_bold'],
                        padding=[30, 12])  # åŠ å¤§æŒ‰é’®
        style.map('Primary.TButton',
                  background=[('active', self.colors['primary_hover']), ('pressed', self.colors['primary_hover'])])
        
        # æˆåŠŸæŒ‰é’® (Success)
        style.configure('Success.TButton', 
                        background=self.colors['success'], 
                        foreground='white',
                        font=self.fonts['body_bold'],
                        padding=[25, 12])  # åŠ å¤§æŒ‰é’®
        style.map('Success.TButton',
                  background=[('active', self.colors['success_hover']), ('pressed', self.colors['success_hover'])])
        
        # è­¦å‘ŠæŒ‰é’® (Warning)
        style.configure('Warning.TButton', 
                        background=self.colors['warning'], 
                        foreground='white',
                        font=self.fonts['body_bold'],
                        padding=[25, 12])  # åŠ å¤§æŒ‰é’®
        style.map('Warning.TButton',
                  background=[('active', self.colors['warning_hover']), ('pressed', self.colors['warning_hover'])])

        # å±é™©æŒ‰é’® (Danger)
        style.configure('Danger.TButton', 
                        background=self.colors['danger'], 
                        foreground='white',
                        font=self.fonts['body_bold'],
                        padding=[20, 10])
        style.map('Danger.TButton',
                  background=[('active', self.colors['danger_hover']), ('pressed', self.colors['danger_hover'])])
        
        # è¾“å…¥æ¡† Entry
        style.configure('TEntry', fieldbackground=self.colors['input_bg'], padding=[10, 8], borderwidth=1, relief='solid')
        style.map('TEntry', bordercolor=[('focus', self.colors['primary'])], lightcolor=[('focus', self.colors['primary'])])
        
        # ä¸‹æ‹‰æ¡† Combobox
        style.configure('TCombobox', fieldbackground=self.colors['input_bg'], padding=[10, 8], arrowsize=15)
        
        # è¿›åº¦æ¡
        style.configure('Horizontal.TProgressbar', background=self.colors['primary'], troughcolor='#e8e8e8', borderwidth=0)
        
        # é€‰é¡¹å¡ Notebook
        style.configure('TNotebook', background=self.colors['bg'], tabmargins=[10, 10, 0, 0], borderwidth=0)
        style.configure('TNotebook.Tab', padding=[10, 8], font=self.fonts['body'], background='#e0e0e0', foreground=self.colors['text_secondary'], width=20, anchor='center')  # å›ºå®šå®½åº¦å’Œå±…ä¸­
        style.map('TNotebook.Tab',
                  background=[('selected', self.colors['card_bg'])],
                  foreground=[('selected', self.colors['primary'])],
                  expand=[('selected', [0, 0, 0, 0])])

        # Labelframe (å…¼å®¹æ—§ä»£ç ï¼Œä½œä¸ºå¡ç‰‡å®¹å™¨)
        style.configure('TLabelframe', background=self.colors['card_bg'], relief='flat')
        style.configure('TLabelframe.Label', background=self.colors['card_bg'], font=self.fonts['h2'], foreground=self.colors['text'])

    def _create_card(self, parent, title=None):
        """åˆ›å»ºä¸€ä¸ªå¡ç‰‡å®¹å™¨"""
        card = ttk.Frame(parent, style='Card.TFrame', padding=20)
        if title:
            ttk.Label(card, text=title, style='CardTitle.TLabel').pack(anchor='w', pady=(0, 15))
        return card

    def _build_ui(self):
        """æ„å»ºæ•´ä½“ UI ç»“æ„"""
        main_frame = self.scrollable_frame
        
        # === é¡¶éƒ¨æ ‡é¢˜æ  ===
        header_frame = ttk.Frame(main_frame)
        header_frame.pack(fill=tk.X, pady=(20, 20), padx=20)
        
        # ä½¿ç”¨å®‰å…¨çš„ Unicode å­—ç¬¦ä½œä¸ºå›¾æ ‡
        icon_label = ttk.Label(header_frame, text="\U0001F6E0", font=("Microsoft YaHei UI", 32)) # ğŸ› ï¸
        icon_label.pack(side=tk.LEFT, padx=(0, 15))
        
        title_box = ttk.Frame(header_frame)
        title_box.pack(side=tk.LEFT)
        ttk.Label(title_box, text="SS14 æ±‰åŒ–å·¥ä½œæµå·¥å…·", style='Title.TLabel').pack(anchor='w')
        ttk.Label(title_box, text="v3.2 | è‡ªåŠ¨åŒ–æå–ä¸åŒæ­¥åŠ©æ‰‹", font=self.fonts['small'], foreground=self.colors['text_secondary']).pack(anchor='w')
        
        # === çŠ¶æ€ä¸è¿›åº¦å¡ç‰‡ ===
        status_card = self._create_card(main_frame, "è¿è¡ŒçŠ¶æ€")
        status_card.pack(fill=tk.X, padx=20, pady=(0, 20))
        
        # è¿›åº¦æ¡
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(status_card, variable=self.progress_var, maximum=100, style='Horizontal.TProgressbar')
        self.progress_bar.pack(fill=tk.X, pady=(0, 10))
        
        # çŠ¶æ€æ–‡æœ¬è¡Œ
        status_row = ttk.Frame(status_card, style='Card.TFrame')
        status_row.pack(fill=tk.X)
        self.status_var = tk.StringVar(value="å½“å‰å°±ç»ª")
        ttk.Label(status_row, text="çŠ¶æ€:", style='Card.TLabel', font=self.fonts['body_bold']).pack(side=tk.LEFT)
        self.progress_label = ttk.Label(status_row, textvariable=self.status_var, style='Card.TLabel', foreground=self.colors['primary'])
        self.progress_label.pack(side=tk.LEFT, padx=(10, 0))
        
        # åœæ­¢æŒ‰é’®å®¹å™¨
        self.stop_frame = ttk.Frame(status_row, style='Card.TFrame')
        self.btn_stop = ttk.Button(self.stop_frame, text="â¹ åœæ­¢è¿è¡Œ", command=self.do_stop, style='Danger.TButton')
        self.btn_stop.pack(side=tk.RIGHT)
        
        # ä¸€é”®å·¥ä½œæµå¡ç‰‡ (ç§»åŠ¨åˆ° Tabs ä¸Šæ–¹)
        self._build_workflow_card(main_frame)
        
        # === æ ¸å¿ƒåŠŸèƒ½åŒº (Notebook) ===
        content_frame = ttk.Frame(main_frame)
        content_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=(0, 20))
        
        self.notebook = ttk.Notebook(content_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        self.tab_extract = ttk.Frame(self.notebook, style='Main.TFrame')
        self.notebook.add(self.tab_extract, text="  æå–åŸæ–‡  ")
        self.setup_extract_tab()
        
        self.tab_sync = ttk.Frame(self.notebook, style='Main.TFrame')
        self.notebook.add(self.tab_sync, text="  Paratranz åŒæ­¥  ")
        self.setup_sync_tab()
        
        self.tab_merge = ttk.Frame(self.notebook, style='Main.TFrame')
        self.notebook.add(self.tab_merge, text="  åˆå¹¶ç¿»è¯‘  ")
        self.setup_merge_tab()
        
        self.tab_settings = ttk.Frame(self.notebook, style='Main.TFrame')
        self.notebook.add(self.tab_settings, text="  è®¾ç½®  ")
        self.setup_settings_tab()
        
        # === æ—¥å¿—åŒºåŸŸ ===
        log_card = self._create_card(main_frame, "è¿è¡Œæ—¥å¿—")
        log_card.pack(fill=tk.BOTH, expand=True, padx=20, pady=(0, 20))
        
        self.log_text = scrolledtext.ScrolledText(
            log_card, height=12, state='disabled',
            font=self.fonts['mono'],
            bg='#1e272e', fg='#dfe6e9',
            insertbackground='white',
            relief='flat', padx=10, pady=10
        )
        self.log_text.pack(fill=tk.BOTH, expand=True)
        
        # é…ç½®æ—¥å¿—é¢œè‰²æ ‡ç­¾
        self.log_text.tag_configure('success', foreground='#00b894')
        self.log_text.tag_configure('error', foreground='#ff7675')
        self.log_text.tag_configure('warning', foreground='#fdcb6e')
        self.log_text.tag_configure('info', foreground='#74b9ff')

    def _build_workflow_card(self, parent):
        """æ„å»ºä¸€é”®å·¥ä½œæµå¡ç‰‡"""
        card = self._create_card(parent)
        card.pack(fill=tk.X, padx=20, pady=(0, 20))
        
        # å·¦å³å¸ƒå±€
        left_side = ttk.Frame(card, style='Card.TFrame')
        left_side.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        ttk.Label(left_side, text="âš¡ ä¸€é”®è‡ªåŠ¨åŒ–å·¥ä½œæµ", style='CardTitle.TLabel', foreground=self.colors['primary']).pack(anchor='w')
        desc = "è‡ªåŠ¨æŒ‰é¡ºåºæ‰§è¡Œï¼šæå–åŸæ–‡ â†’ ä¸Šä¼ åˆ° Paratranz â†’ ä¸‹è½½æœ€æ–°ç¿»è¯‘ â†’ åˆå¹¶å›æ¸¸æˆæ–‡ä»¶ã€‚\né€‚åˆæ—¥å¸¸åŒæ­¥æ›´æ–°ä½¿ç”¨ã€‚"
        ttk.Label(left_side, text=desc, style='Card.TLabel', foreground=self.colors['text_secondary']).pack(anchor='w', pady=(5, 0))
        
        right_side = ttk.Frame(card, style='Card.TFrame')
        right_side.pack(side=tk.RIGHT, padx=(20, 0))
        
        self.btn_workflow = ttk.Button(right_side, text="å¼€å§‹ä¸€é”®åŒæ­¥", command=self.do_full_workflow, style='Primary.TButton')
        self.btn_workflow.pack()

    def auto_detect_directory(self):
        """å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹æ¸¸æˆç›®å½•"""
        detected = detect_game_directory()
        if detected:
            self.extract_dir_var.set(detected)
            self.merge_source_var.set(detected)
            self.log(f"è‡ªåŠ¨æ£€æµ‹åˆ°æ¸¸æˆç›®å½•: {detected}")

    def _on_canvas_configure(self, event):
        """å½“ Canvas å¤§å°å˜åŒ–æ—¶ï¼Œè°ƒæ•´å†…éƒ¨ Frame å®½åº¦ä»¥åŒ¹é…"""
        self.canvas.itemconfig(self.canvas_window, width=event.width)
    
    def _bind_mousewheel(self):
        """ç»‘å®šé¼ æ ‡æ»šè½®äº‹ä»¶ï¼ˆè·¨å¹³å°æ”¯æŒï¼‰"""
        # ç›´æ¥ç»‘å®šåˆ° root çª—å£ï¼Œç¡®ä¿åœ¨ä»»ä½•ä½ç½®éƒ½èƒ½å“åº”æ»šè½®
        self.root.bind("<MouseWheel>", self._on_mousewheel)
        self.root.bind("<Button-4>", self._on_mousewheel)  # Linux scroll up
        self.root.bind("<Button-5>", self._on_mousewheel)  # Linux scroll down
        
        # åŒæ—¶ä¹Ÿç»‘å®šåˆ° canvas å’Œ scrollable_frame
        self.canvas.bind("<MouseWheel>", self._on_mousewheel)
        self.scrollable_frame.bind("<MouseWheel>", self._on_mousewheel)
        
        # é€’å½’ç»‘å®šæ‰€æœ‰å­æ§ä»¶
        self.root.after(100, self._bind_children_mousewheel)
    
    def _bind_children_mousewheel(self):
        """é€’å½’ç»™æ‰€æœ‰å­æ§ä»¶ç»‘å®šé¼ æ ‡æ»šè½®äº‹ä»¶"""
        def bind_recursive(widget):
            try:
                widget.bind("<MouseWheel>", self._on_mousewheel)
                widget.bind("<Button-4>", self._on_mousewheel)
                widget.bind("<Button-5>", self._on_mousewheel)
            except:
                pass
            for child in widget.winfo_children():
                bind_recursive(child)
        
        bind_recursive(self.scrollable_frame)
    
    def _on_mousewheel(self, event):
        """å¤„ç†é¼ æ ‡æ»šè½®æ»šåŠ¨"""
        # æ£€æŸ¥ canvas æ˜¯å¦å­˜åœ¨ä¸”å†…å®¹æ˜¯å¦è¶…å‡ºè§†å£
        try:
            bbox = self.canvas.bbox("all")
            if bbox:
                canvas_height = self.canvas.winfo_height()
                content_height = bbox[3] - bbox[1]
                
                # åªåœ¨å†…å®¹è¶…å‡ºè§†å£æ—¶æ»šåŠ¨
                if content_height > canvas_height:
                    # Windows/MacOS
                    if hasattr(event, 'delta') and event.delta != 0:
                        self.canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")
                    # Linux scroll up
                    elif event.num == 4:
                        self.canvas.yview_scroll(-1, "units")
                    # Linux scroll down
                    elif event.num == 5:
                        self.canvas.yview_scroll(1, "units")
        except:
            pass

    def load_config(self) -> Dict:
        default_config = {
            "extract_dir": "Resources/Prototypes",
            "extract_output": "en.json",
            "pz_token": "",
            "pz_project_id": "16648",
            "merge_source": "Resources/Prototypes",
            "merge_input": "zh.json",
            "download_path": "zh.json",
            "upload_path": "",  # æ–°å¢ï¼šè‡ªå®šä¹‰ä¸Šä¼ è·¯å¾„
            "translatable_fields": DEFAULT_TRANSLATABLE_FIELDS,
            # è·¯å¾„å†å²è®°å½•
            "history_extract_dir": [],
            "history_extract_output": [],
            "history_download_path": [],
            "history_upload_path": [],  # æ–°å¢
            "history_merge_input": [],
            "history_merge_source": []
        }
        if os.path.exists(CONFIG_FILE):
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    return {**default_config, **json.load(f)}
            except:
                return default_config
        return default_config

    def save_config(self):
        self.config["extract_dir"] = self.extract_dir_var.get()
        self.config["extract_output"] = self.extract_output_var.get()
        self.config["pz_token"] = self.pz_token_var.get()
        self.config["pz_project_id"] = self.pz_project_id_var.get()
        self.config["merge_source"] = self.merge_source_var.get()
        self.config["merge_input"] = self.merge_input_var.get()
        self.config["download_path"] = self.download_path_var.get()
        if hasattr(self, 'upload_path_var'):
            self.config["upload_path"] = self.upload_path_var.get()
        self.config["translatable_fields"] = [f.strip() for f in self.fields_var.get().split(',')]
        # æ–°å¢é€‰é¡¹
        self.config["filter_ftl"] = self.filter_ftl_var.get()
        self.config["by_folder"] = self.by_folder_var.get()
        
        # ä¿å­˜è·¯å¾„å†å²è®°å½•ï¼ˆä»å„ä¸ª Combobox è·å–ï¼‰
        if hasattr(self, 'combo_extract_dir'):
            self.config["history_extract_dir"] = list(self.combo_extract_dir['values'])
        if hasattr(self, 'combo_extract_output'):
            self.config["history_extract_output"] = list(self.combo_extract_output['values'])
        if hasattr(self, 'combo_download_path'):
            self.config["history_download_path"] = list(self.combo_download_path['values'])
        if hasattr(self, 'combo_upload_path'):
            self.config["history_upload_path"] = list(self.combo_upload_path['values'])
        if hasattr(self, 'combo_merge_input'):
            self.config["history_merge_input"] = list(self.combo_merge_input['values'])
        if hasattr(self, 'combo_merge_source'):
            self.config["history_merge_source"] = list(self.combo_merge_source['values'])
        
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=4, ensure_ascii=False)

    def on_close(self):
        self.save_config()
        self.root.destroy()

    def update_gui_log(self):
        """ä»é˜Ÿåˆ—ä¸­è·å–æ—¥å¿—å¹¶æ›´æ–°åˆ° GUI"""
        logs = gui_log_handler.pop_logs()
        if not logs:
            return
            
        def _update():
            try:
                self.log_text.config(state='normal')
                for levelname, message in logs:
                    tag = None
                    if levelname in ['ERROR', 'CRITICAL'] or 'âŒ' in message or 'Error' in message:
                        tag = 'error'
                    elif levelname == 'WARNING' or 'âš ï¸' in message or 'Warning' in message:
                        tag = 'warning'
                    elif 'âœ…' in message or 'æˆåŠŸ' in message or 'å®Œæˆ' in message:
                        tag = 'success'
                    elif 'INFO' in message or 'â„¹ï¸' in message or 'ğŸ“‚' in message or 'ğŸ“„' in message:
                        tag = 'info'
                    
                    if tag:
                        self.log_text.insert(tk.END, message + "\n", tag)
                    else:
                        self.log_text.insert(tk.END, message + "\n")
                
                # é™åˆ¶ç¼“å†²åŒºå¤§å° (çº¦ 5000 è¡Œ)
                try:
                    index = self.log_text.index('end-1c')
                    line_count = int(index.split('.')[0])
                    if line_count > 5000:
                        self.log_text.delete('1.0', f'{line_count - 5000}.0')
                except Exception:
                    pass
                
                self.log_text.see(tk.END)
            except Exception:
                pass
            finally:
                self.log_text.config(state='disabled')
            
        self.root.after(0, _update)

    def log(self, message: str, level: str = "INFO"):
        """è¾“å‡ºæ—¥å¿— (ä»£ç†åˆ°å…¨å±€ logging)"""
        log(message, level)

    def update_progress(self, current: int, total: int, message: str = ""):
        def _update():
            if total > 0:
                percent = (current / total) * 100
                self.progress_var.set(percent)
                self.progress_label.config(text=f"{current}/{total} - {message[:30]}")
        self.root.after(0, _update)

    def run_in_thread(self, func, *args, success_msg="æ“ä½œæˆåŠŸå®Œæˆï¼"):
        """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå‡½æ•°"""
        if self.is_running:
            messagebox.showwarning("æç¤º", "æœ‰æ“ä½œæ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨å€™...")
            return
        
        def _show_stop_button():
            """æ˜¾ç¤ºåœæ­¢æŒ‰é’®"""
            self.stop_frame.pack(fill=tk.X, pady=(10, 0))
        
        def _hide_stop_button():
            """éšè—åœæ­¢æŒ‰é’®"""
            self.stop_frame.pack_forget()
            
        def _run():
            self.is_running = True
            self.stop_requested = False
            self.status_var.set("æ­£åœ¨è¿è¡Œ...")
            self.progress_var.set(0)
            
            # æ˜¾ç¤ºåœæ­¢æŒ‰é’®
            self.root.after(0, _show_stop_button)
            
            # è®¾ç½®è¿›åº¦å›è°ƒå’Œåœæ­¢æ£€æŸ¥å›è°ƒ
            set_progress_callback(self.update_progress)
            set_stop_check_callback(lambda: self.stop_requested)
            
            try:
                result = func(*args)
                
                if self.stop_requested:
                    self.log("â¹ æ“ä½œå·²è¢«ç”¨æˆ·åœæ­¢")
                    self.status_var.set("å·²åœæ­¢")
                elif result is False:
                    self.log("âŒ æ“ä½œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—ã€‚")
                    self.status_var.set("æ“ä½œå¤±è´¥")
                    self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", "æ“ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ã€‚"))
                else:
                    self.log(f"âœ… {success_msg}")
                    self.status_var.set("æ“ä½œæˆåŠŸ")
                    self.progress_var.set(100)
                    self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", success_msg))
                    
            except Exception as e:
                if self.stop_requested:
                    self.log("â¹ æ“ä½œå·²è¢«ç”¨æˆ·åœæ­¢")
                    self.status_var.set("å·²åœæ­¢")
                else:
                    self.log(f"âŒ å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                    self.status_var.set("å‘ç”Ÿé”™è¯¯")
                    self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"è¿è¡Œå¼‚å¸¸: {e}"))
            finally:
                self.is_running = False
                self.stop_requested = False
                set_progress_callback(None)
                set_stop_check_callback(None)
                # éšè—åœæ­¢æŒ‰é’®
                self.root.after(0, _hide_stop_button)

        threading.Thread(target=_run, daemon=True).start()

    def do_stop(self):
        """è¯·æ±‚åœæ­¢å½“å‰æ“ä½œ"""
        if self.is_running:
            self.stop_requested = True
            self.log("â³ æ­£åœ¨åœæ­¢ï¼Œè¯·ç¨å€™...")
            self.status_var.set("æ­£åœ¨åœæ­¢...")

    # ===== ç•Œé¢è®¾ç½® =====

    def setup_extract_tab(self):
        frame = self.tab_extract
        
        # è¾“å…¥åŒºåŸŸå®¹å™¨
        input_card = self._create_card(frame, 'ğŸ“ è·¯å¾„è®¾ç½®')
        input_card.pack(fill=tk.X, pady=(0, 20))
        
        # æ‰«æç›®å½•
        row1 = ttk.Frame(input_card, style='Card.TFrame')
        row1.pack(fill=tk.X, pady=5)
        ttk.Label(row1, text="æ‰«æç›®å½•:", width=14, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.extract_dir_var = tk.StringVar(value=self.config["extract_dir"])
        self.combo_extract_dir = ttk.Combobox(row1, textvariable=self.extract_dir_var, width=50)
        self.combo_extract_dir['values'] = self.config.get("history_extract_dir", [])
        self.combo_extract_dir.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.combo_extract_dir.bind("<Button-3>", 
            lambda e: self.show_history_context_menu(e, self.combo_extract_dir, self.extract_dir_var))
        ttk.Button(row1, text="æµè§ˆ...", 
            command=lambda: self.select_folder(self.extract_dir_var, self.combo_extract_dir)).pack(side=tk.LEFT)
        
        # è¾“å‡ºæ–‡ä»¶/ç›®å½•
        row2 = ttk.Frame(input_card, style='Card.TFrame')
        row2.pack(fill=tk.X, pady=5)
        ttk.Label(row2, text="è¾“å‡ºæ–‡ä»¶/ç›®å½•:", width=14, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.extract_output_var = tk.StringVar(value=self.config["extract_output"])
        self.combo_extract_output = ttk.Combobox(row2, textvariable=self.extract_output_var, width=50)
        self.combo_extract_output['values'] = self.config.get("history_extract_output", [])
        self.combo_extract_output.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.combo_extract_output.bind("<Button-3>", 
            lambda e: self.show_history_context_menu(e, self.combo_extract_output, self.extract_output_var))
        ttk.Button(row2, text="æµè§ˆ...", command=self._select_extract_output).pack(side=tk.LEFT)
        
        # æç¤ºæ ‡ç­¾
        ttk.Label(input_card, text="ğŸ’¡ å³é”®ç‚¹å‡»è¾“å…¥æ¡†å¯ç®¡ç†å†å²è®°å½•", 
                  style='Hint.TLabel').pack(anchor='w', pady=(5, 0))
        
        # é€‰é¡¹åŒºåŸŸ
        options_card = self._create_card(frame, "âš™ï¸ æå–é€‰é¡¹")
        options_card.pack(fill=tk.X, pady=(0, 20))
        
        # FTL è¿‡æ»¤é€‰é¡¹
        self.filter_ftl_var = tk.BooleanVar(value=self.config.get("filter_ftl", True))
        ttk.Checkbutton(options_card, text="è¿‡æ»¤ FTL æœ¬åœ°åŒ–é”®å€¼ (è·³è¿‡ loadout-group-weapon ç±»)", 
                       variable=self.filter_ftl_var, style='Card.TCheckbutton').pack(anchor='w', pady=3)
        
        # æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„é€‰é¡¹
        self.by_folder_var = tk.BooleanVar(value=self.config.get("by_folder", False))
        ttk.Checkbutton(options_card, text="æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æå– (ä¿ç•™å®Œæ•´ç›®å½•ç»“æ„ï¼Œç”Ÿæˆå¤šä¸ª JSON)", 
                       variable=self.by_folder_var, style='Card.TCheckbutton').pack(anchor='w', pady=3)
        
        # æŒ‰é’®å±…ä¸­åŒºåŸŸ
        btn_frame = ttk.Frame(frame, style='Main.TFrame')
        btn_frame.pack(fill=tk.X, pady=10)
        
        ttk.Button(btn_frame, text="â–¶ï¸ å¼€å§‹æå–", command=self.do_extract,
                   style='Primary.TButton').pack(anchor='center')

    def _select_extract_output(self):
        """é€‰æ‹©æå–è¾“å‡ºä½ç½®ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼‰"""
        if self.by_folder_var.get():
            # æŒ‰æ–‡ä»¶å¤¹æ¨¡å¼ï¼šé€‰æ‹©ç›®å½•
            folder = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºç›®å½•")
            if folder:
                self.extract_output_var.set(folder)
                self.add_to_history(self.combo_extract_output, folder)
        else:
            # å•æ–‡ä»¶æ¨¡å¼ï¼šé€‰æ‹©æ–‡ä»¶
            file = filedialog.asksaveasfilename(
                defaultextension=".json",
                filetypes=[("JSON files", "*.json"), ("All files", "*.*")],
                initialfile="en.json"
            )
            if file:
                self.extract_output_var.set(file)
                self.add_to_history(self.combo_extract_output, file)

    def setup_sync_tab(self):
        frame = self.tab_sync
        
        # API è®¾ç½®åŒºåŸŸ
        api_card = self._create_card(frame, "\U0001F511 API è®¾ç½®")
        api_card.pack(fill=tk.X, pady=(0, 20))
        
        # é¡¹ç›® ID
        row1 = ttk.Frame(api_card, style='Card.TFrame')
        row1.pack(fill=tk.X, pady=5)
        ttk.Label(row1, text="é¡¹ç›® ID:", width=14, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.pz_project_id_var = tk.StringVar(value=self.config["pz_project_id"])
        ttk.Entry(row1, textvariable=self.pz_project_id_var, width=20).pack(side=tk.LEFT)
        ttk.Label(row1, text="(Paratranz é¡¹ç›®ç¼–å·)", 
                  style='Hint.TLabel').pack(side=tk.LEFT, padx=(10, 0))
        
        # API Token
        row2 = ttk.Frame(api_card, style='Card.TFrame')
        row2.pack(fill=tk.X, pady=5)
        ttk.Label(row2, text="API Token:", width=14, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.pz_token_var = tk.StringVar(value=self.config["pz_token"])
        ttk.Entry(row2, textvariable=self.pz_token_var, width=50, show="*").pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        # æ–‡ä»¶è·¯å¾„è®¾ç½®åŒºåŸŸ
        path_card = self._create_card(frame, "\U0001F4C1 æ–‡ä»¶è·¯å¾„")
        path_card.pack(fill=tk.X, pady=(0, 20))
        
        # ä¸Šä¼ è·¯å¾„
        row3 = ttk.Frame(path_card, style='Card.TFrame')
        row3.pack(fill=tk.X, pady=5)
        ttk.Label(row3, text="ä¸Šä¼ æ–‡ä»¶/ç›®å½•:", width=14, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.upload_path_var = tk.StringVar(value=self.config.get("upload_path", ""))
        self.combo_upload_path = ttk.Combobox(row3, textvariable=self.upload_path_var, width=42)
        self.combo_upload_path['values'] = self.config.get("history_upload_path", [])
        self.combo_upload_path.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.combo_upload_path.bind("<Button-3>", 
            lambda e: self.show_history_context_menu(e, self.combo_upload_path, self.upload_path_var))
        
        # æµè§ˆæŒ‰é’®åŒºåŸŸ
        browse_frame = ttk.Frame(row3, style='Card.TFrame')
        browse_frame.pack(side=tk.LEFT)
        ttk.Button(browse_frame, text="ğŸ“„ æ–‡ä»¶", width=7,
            command=self._select_upload_file).pack(side=tk.LEFT, padx=(0, 3))
        ttk.Button(browse_frame, text="ğŸ“ ç›®å½•", width=7,
            command=self._select_upload_folder).pack(side=tk.LEFT)
        
        # Download Path
        row4 = ttk.Frame(path_card, style='Card.TFrame')
        row4.pack(fill=tk.X, pady=5)
        ttk.Label(row4, text="ä¸‹è½½ä¿å­˜è·¯å¾„:", width=14, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.download_path_var = tk.StringVar(value=self.config.get("download_path", "zh.json"))
        self.combo_download_path = ttk.Combobox(row4, textvariable=self.download_path_var, width=42)
        self.combo_download_path['values'] = self.config.get("history_download_path", [])
        self.combo_download_path.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.combo_download_path.bind("<Button-3>", 
            lambda e: self.show_history_context_menu(e, self.combo_download_path, self.download_path_var))
        ttk.Button(row4, text="æµè§ˆ...", command=self._select_download_path).pack(side=tk.LEFT)
        
        # Hint
        ttk.Label(path_card, text="ğŸ’¡ å³é”®ç‚¹å‡»è¾“å…¥æ¡†å¯ç®¡ç†å†å²è®°å½•", 
                  style='Hint.TLabel').pack(anchor='w', pady=(5, 0))
        
        # Buttons
        btn_frame = ttk.Frame(frame, style='Main.TFrame')
        btn_frame.pack(fill=tk.X, pady=10)
        
        btn_inner = ttk.Frame(btn_frame, style='Main.TFrame')
        btn_inner.pack(anchor='center')
        
        ttk.Button(btn_inner, text="ğŸ”— æµ‹è¯•è¿æ¥", command=self.do_test_connection).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_inner, text="â¬†ï¸ ä¸Šä¼ ", command=self.do_upload,
                   style='Primary.TButton').pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_inner, text="â¬‡ï¸ ä¸‹è½½", command=self.do_download,
                   style='Success.TButton').pack(side=tk.LEFT, padx=5)

    def _select_download_path(self):
        """é€‰æ‹©ä¸‹è½½ä¿å­˜ä½ç½®"""
        file = filedialog.asksaveasfilename(
            defaultextension=".json",
            filetypes=[("JSON files", "*.json"), ("All files", "*.*")],
            initialfile="zh.json"
        )
        if file:
            self.download_path_var.set(file)
            self.add_to_history(self.combo_download_path, file)

    def _select_upload_file(self):
        """é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶"""
        file = filedialog.askopenfilename(
            filetypes=[("JSON files", "*.json"), ("All files", "*.*")]
        )
        if file:
            self.upload_path_var.set(file)
            self.add_to_history(self.combo_upload_path, file)

    def _select_upload_folder(self):
        """é€‰æ‹©è¦ä¸Šä¼ çš„ç›®å½•"""
        folder = filedialog.askdirectory(title="é€‰æ‹©åŒ…å« JSON æ–‡ä»¶çš„ç›®å½•")
        if folder:
            self.upload_path_var.set(folder)
            self.add_to_history(self.combo_upload_path, folder)

    def setup_merge_tab(self):
        frame = self.tab_merge
        
        # æ–‡ä»¶è®¾ç½®åŒºåŸŸ
        file_card = self._create_card(frame, "\U0001F4C4 æ–‡ä»¶è®¾ç½®")
        file_card.pack(fill=tk.X, pady=(0, 20))
        
        # ç¿»è¯‘æ–‡ä»¶
        row1 = ttk.Frame(file_card, style='Card.TFrame')
        row1.pack(fill=tk.X, pady=5)
        ttk.Label(row1, text="ç¿»è¯‘æ–‡ä»¶:", width=12, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.merge_input_var = tk.StringVar(value=self.config["merge_input"])
        self.combo_merge_input = ttk.Combobox(row1, textvariable=self.merge_input_var, width=50)
        self.combo_merge_input['values'] = self.config.get("history_merge_input", [])
        self.combo_merge_input.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.combo_merge_input.bind("<Button-3>", 
            lambda e: self.show_history_context_menu(e, self.combo_merge_input, self.merge_input_var))
        ttk.Button(row1, text="æµè§ˆ...", 
            command=lambda: self.select_file(self.merge_input_var, self.combo_merge_input)).pack(side=tk.LEFT)
        
        # ç›®æ ‡ç›®å½•
        row2 = ttk.Frame(file_card, style='Card.TFrame')
        row2.pack(fill=tk.X, pady=5)
        ttk.Label(row2, text="ç›®æ ‡ç›®å½•:", width=12, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        self.merge_source_var = tk.StringVar(value=self.config["merge_source"])
        self.combo_merge_source = ttk.Combobox(row2, textvariable=self.merge_source_var, width=50)
        self.combo_merge_source['values'] = self.config.get("history_merge_source", [])
        self.combo_merge_source.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        self.combo_merge_source.bind("<Button-3>", 
            lambda e: self.show_history_context_menu(e, self.combo_merge_source, self.merge_source_var))
        ttk.Button(row2, text="æµè§ˆ...", 
            command=lambda: self.select_folder(self.merge_source_var, self.combo_merge_source)).pack(side=tk.LEFT)
        
        # æç¤ºæ ‡ç­¾
        ttk.Label(file_card, text="ğŸ’¡ å³é”®ç‚¹å‡»è¾“å…¥æ¡†å¯ç®¡ç†å†å²è®°å½•", 
                  style='Hint.TLabel').pack(anchor='w', pady=(5, 0))
        
        # è­¦å‘ŠåŒºåŸŸ
        warning_card = self._create_card(frame)
        warning_card.pack(fill=tk.X, pady=(0, 20))
        
        warning_label = ttk.Label(warning_card, 
            text="âš ï¸ æ³¨æ„ï¼šåˆå¹¶æ“ä½œä¼šä¿®æ”¹ç›®æ ‡ç›®å½•ä¸­çš„ YAML æ–‡ä»¶ï¼Œæ“ä½œå‰å»ºè®®å¤‡ä»½ï¼",
            foreground=self.colors['danger'],
            font=self.default_font_bold, style='Card.TLabel')
        warning_label.pack(anchor='center')
        
        # æŒ‰é’®å±…ä¸­åŒºåŸŸ
        btn_frame = ttk.Frame(frame, style='Main.TFrame')
        btn_frame.pack(fill=tk.X, pady=15)
        
        ttk.Button(btn_frame, text="ğŸ”€ å¼€å§‹åˆå¹¶", command=self.do_merge,
                   style='Warning.TButton').pack(anchor='center')

    def setup_settings_tab(self):
        frame = self.tab_settings
        
        # å­—æ®µè®¾ç½®åŒºåŸŸ
        fields_card = self._create_card(frame, "\U0001F527 ç¿»è¯‘å­—æ®µè®¾ç½®")
        fields_card.pack(fill=tk.X, pady=(0, 20))
        
        row1 = ttk.Frame(fields_card, style='Card.TFrame')
        row1.pack(fill=tk.X, pady=5)
        ttk.Label(row1, text="å¯ç¿»è¯‘å­—æ®µ:", width=12, anchor='e', style='Card.TLabel').pack(side=tk.LEFT, padx=(0, 10))
        fields_str = ', '.join(self.config.get("translatable_fields", DEFAULT_TRANSLATABLE_FIELDS))
        self.fields_var = tk.StringVar(value=fields_str)
        ttk.Entry(row1, textvariable=self.fields_var, width=50).pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        ttk.Label(fields_card, text="ğŸ’¡ å¤šä¸ªå­—æ®µç”¨é€—å·åˆ†éš”ï¼Œé»˜è®¤: name, description", 
                  style='Hint.TLabel').pack(anchor='w', pady=(5, 0))
        
        # è¯´æ˜åŒºåŸŸ
        info_card = self._create_card(frame, "\U00002139\U0000FE0F ä½¿ç”¨è¯´æ˜")
        info_card.pack(fill=tk.X, pady=(0, 20))
        
        info_text = """å·¥ä½œæµç¨‹è¯´æ˜ï¼š
1. æå–åŸæ–‡ï¼šä»æ¸¸æˆ YAML æ–‡ä»¶ä¸­æå–å¯ç¿»è¯‘çš„æ–‡æœ¬
2. Paratranz åŒæ­¥ï¼šå°†æå–çš„æ–‡æœ¬ä¸Šä¼ åˆ° Paratranz å¹³å°è¿›è¡Œç¿»è¯‘
3. ä¸‹è½½ç¿»è¯‘ï¼šä» Paratranz ä¸‹è½½ç¿»è¯‘å®Œæˆçš„æ–‡æœ¬
4. åˆå¹¶ç¿»è¯‘ï¼šå°†ç¿»è¯‘æ–‡æœ¬åˆå¹¶å›æ¸¸æˆ YAML æ–‡ä»¶

æ¨èä½¿ç”¨ã€Œä¸€é”®å·¥ä½œæµã€è‡ªåŠ¨å®Œæˆä»¥ä¸Šæ‰€æœ‰æ­¥éª¤ã€‚"""
        
        ttk.Label(info_card, text=info_text, justify='left',
                  style='Card.TLabel').pack(anchor='w')
        
        # æŒ‰é’®å±…ä¸­åŒºåŸŸ
        btn_frame = ttk.Frame(frame, style='Main.TFrame')
        btn_frame.pack(fill=tk.X, pady=20)
        
        ttk.Button(btn_frame, text="ğŸ’¾ ä¿å­˜è®¾ç½®", command=self.save_config,
                   style='Primary.TButton').pack(anchor='center')

    def select_folder(self, var, combo=None):
        """é€‰æ‹©æ–‡ä»¶å¤¹ï¼Œå¯é€‰åœ°æ›´æ–°åˆ° Combobox å†å²"""
        folder = filedialog.askdirectory()
        if folder:
            var.set(folder)
            if combo:
                self.add_to_history(combo, folder)

    def select_file(self, var, combo=None, filetypes=None):
        """é€‰æ‹©æ–‡ä»¶ï¼Œå¯é€‰åœ°æ›´æ–°åˆ° Combobox å†å²"""
        if filetypes is None:
            filetypes = [("JSON files", "*.json"), ("All files", "*.*")]
        file = filedialog.askopenfilename(filetypes=filetypes)
        if file:
            var.set(file)
            if combo:
                self.add_to_history(combo, file)

    def add_to_history(self, combo, value, max_items=15):
        """å°†æ–°å€¼æ·»åŠ åˆ° Combobox å†å²è®°å½•ï¼ˆæœ€å¤šä¿ç•™ max_items æ¡ï¼‰"""
        if not value or not value.strip():
            return
        value = value.strip()
        current_values = list(combo['values'])
        # å»é‡ï¼šå¦‚æœå·²å­˜åœ¨åˆ™ç§»åˆ°æœ€å‰é¢
        if value in current_values:
            current_values.remove(value)
        current_values.insert(0, value)
        # é™åˆ¶æœ€å¤§æ•°é‡
        combo['values'] = current_values[:max_items]

    def show_history_context_menu(self, event, combo, var):
        """æ˜¾ç¤ºå³é”®èœå•ï¼Œç”¨äºç®¡ç†å†å²è®°å½•"""
        menu = tk.Menu(self.root, tearoff=0)
        current_values = list(combo['values'])
        
        if not current_values:
            menu.add_command(label="(æ— å†å²è®°å½•)", state='disabled')
        else:
            menu.add_command(label="ğŸ“‹ å†å²è®°å½•", state='disabled')
            menu.add_separator()
            # æ˜¾ç¤ºæœ€å¤š10æ¡å†å²è®°å½•ä¾›é€‰æ‹©
            for i, val in enumerate(current_values[:10]):
                display = val if len(val) < 50 else "..." + val[-47:]
                menu.add_command(label=f"  {display}", 
                               command=lambda v=val: var.set(v))
            if len(current_values) > 10:
                menu.add_command(label=f"  ...è¿˜æœ‰ {len(current_values) - 10} æ¡", state='disabled')
            
            menu.add_separator()
            menu.add_command(label="ğŸ—‘ï¸ åˆ é™¤å½“å‰é€‰ä¸­é¡¹", 
                           command=lambda: self.delete_history_item(combo, var.get()))
            menu.add_command(label="ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰å†å²", 
                           command=lambda: self.clear_history(combo))
        
        try:
            menu.tk_popup(event.x_root, event.y_root)
        finally:
            menu.grab_release()

    def delete_history_item(self, combo, value):
        """åˆ é™¤æŒ‡å®šçš„å†å²è®°å½•é¡¹"""
        current_values = list(combo['values'])
        if value in current_values:
            current_values.remove(value)
            combo['values'] = current_values
            self.log(f"å·²åˆ é™¤å†å²è®°å½•: {value}")

    def clear_history(self, combo):
        """æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•"""
        combo['values'] = []
        self.log("å·²æ¸…ç©ºå†å²è®°å½•")

    # ===== æ“ä½œå‡½æ•° =====

    def get_fields(self) -> List[str]:
        return [f.strip() for f in self.fields_var.get().split(',') if f.strip()]

    def do_extract(self):
        target = self.extract_dir_var.get()
        output = self.extract_output_var.get()
        if not target or not output:
            messagebox.showwarning("æç¤º", "è¯·å¡«å†™ç›®å½•å’Œè¾“å‡ºæ–‡ä»¶/ç›®å½•")
            return
        
        filter_ftl = self.filter_ftl_var.get()
        by_folder = self.by_folder_var.get()
        fields = self.get_fields()
        
        if by_folder:
            # æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æ¨¡å¼
            self.run_in_thread(extract_strings_by_folder, target, output, fields, 
                              filter_ftl,
                              success_msg="æå–å®Œæˆï¼")
        else:
            # å•æ–‡ä»¶æ¨¡å¼
            self.run_in_thread(extract_strings, target, output, fields, 
                              False, filter_ftl,  # incremental=False, filter_ftl
                              success_msg="æå–å®Œæˆï¼")

    def do_test_connection(self):
        token = self.pz_token_var.get()
        pid = self.pz_project_id_var.get()
        if not token or not pid:
            messagebox.showwarning("æç¤º", "è¯·å¡«å†™é¡¹ç›® ID å’Œ Token")
            return
        
        def _test():
            client = PZClient(int(pid), token)
            return client.test_connection()
        
        self.run_in_thread(_test, success_msg="è¿æ¥æµ‹è¯•æˆåŠŸï¼")

    def do_upload(self):
        token = self.pz_token_var.get()
        pid = self.pz_project_id_var.get()
        
        # ä¼˜å…ˆä½¿ç”¨åŒæ­¥é€‰é¡¹å¡çš„ä¸Šä¼ è·¯å¾„ï¼Œå¦‚æœä¸ºç©ºåˆ™å›é€€åˆ°æå–è¾“å‡ºè·¯å¾„
        target = self.upload_path_var.get().strip() if hasattr(self, 'upload_path_var') else ""
        if not target:
            target = self.extract_output_var.get()
        
        if not token:
            messagebox.showwarning("æç¤º", "è¯·è¾“å…¥ Token")
            return
        if not target:
            messagebox.showwarning("æç¤º", "è¯·åœ¨ã€Œä¸Šä¼ æ–‡ä»¶/ç›®å½•ã€ä¸­æŒ‡å®šè¦ä¸Šä¼ çš„è·¯å¾„")
            return
        if not os.path.exists(target):
            messagebox.showwarning("æç¤º", f"æŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨: {target}")
            return
        
        def _upload():
            client = PZClient(int(pid), token)
            # è‡ªåŠ¨æ£€æµ‹ï¼šå¦‚æœæ˜¯ç›®å½•åˆ™æ‰¹é‡ä¸Šä¼ ï¼Œå¦åˆ™ä¸Šä¼ å•æ–‡ä»¶
            if os.path.isdir(target):
                self.log(f"ğŸ“‚ æ£€æµ‹åˆ°ç›®å½•ï¼Œä½¿ç”¨æ‰¹é‡ä¸Šä¼ æ¨¡å¼: {target}")
                result = client.upload_folder(target)
                return result.get("uploaded", 0) > 0 or result.get("failed", 0) == 0
            else:
                self.log(f"ğŸ“„ ä¸Šä¼ å•æ–‡ä»¶: {target}")
                return client.upload_file(target)
        
        self.run_in_thread(_upload, success_msg="ä¸Šä¼ æˆåŠŸï¼")

    def do_download(self):
        token = self.pz_token_var.get()
        pid = self.pz_project_id_var.get()
        local_file = self.download_path_var.get()  # ä½¿ç”¨æ–°çš„ä¸‹è½½è·¯å¾„å˜é‡
        if not token:
            messagebox.showwarning("æç¤º", "è¯·è¾“å…¥ Token")
            return
        if not local_file:
            messagebox.showwarning("æç¤º", "è¯·æŒ‡å®šä¸‹è½½ä¿å­˜è·¯å¾„")
            return
        
        def _download():
            client = PZClient(int(pid), token)
            return client.download_file(local_file)
        
        self.run_in_thread(_download, success_msg=f"ä¸‹è½½æˆåŠŸï¼å·²ä¿å­˜åˆ°: {local_file}")

    def do_merge(self):
        input_file = self.merge_input_var.get()
        target_dir = self.merge_source_var.get()
        if not os.path.exists(input_file):
            messagebox.showwarning("é”™è¯¯", f"æ‰¾ä¸åˆ°ç¿»è¯‘æ–‡ä»¶ï¼š{input_file}")
            return
        self.run_in_thread(merge_translations, target_dir, input_file, target_dir, self.get_fields(),
                          success_msg="åˆå¹¶å®Œæˆï¼")

    def do_full_workflow(self):
        """æ‰§è¡Œä¸€é”®å·¥ä½œæµ"""
        token = self.pz_token_var.get()
        pid = self.pz_project_id_var.get()
        
        if not token:
            messagebox.showwarning("æç¤º", "è¯·å…ˆåœ¨ã€ŒParatranz åŒæ­¥ã€é€‰é¡¹å¡ä¸­å¡«å†™ API Token")
            self.notebook.select(self.tab_sync)
            return
        
        scan_dir = self.extract_dir_var.get()
        output_json = self.extract_output_var.get()
        translation_json = self.merge_input_var.get()
        output_dir = self.merge_source_var.get()
        fields = self.get_fields()
        
        # è¯»å–åˆ†ç»„æ¨¡å¼é€‰é¡¹
        by_folder = self.by_folder_var.get()
        filter_ftl = self.filter_ftl_var.get()
        
        self.run_in_thread(
            run_full_workflow,
            scan_dir, output_json, translation_json,
            int(pid), token, output_dir, fields,
            by_folder, filter_ftl,
            success_msg="ä¸€é”®å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼"
        )

# ==================== ä¸»ç¨‹åºå…¥å£ (Main) ====================

if __name__ == "__main__":
    setup_logging()
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œå¯åŠ¨ GUI
    if len(sys.argv) == 1:
        try:
            root = tk.Tk()
            app = App(root)
            root.mainloop()
        except Exception as e:
            with open("error_log.txt", "w") as f:
                import traceback
                f.write(traceback.format_exc())
    # å¦åˆ™è§£æå‘½ä»¤è¡Œå‚æ•°
    else:
        parser = argparse.ArgumentParser(description="SS14 Localization Tracker CLI v3.0")
        subparsers = parser.add_subparsers(dest='command')
        
        # Extract å‘½ä»¤
        p_extract = subparsers.add_parser('extract', help='Extract strings')
        p_extract.add_argument('--source', help='Source repo root (Optional)')
        p_extract.add_argument('--target_folders', required=True, help='Target directory')
        p_extract.add_argument('--output', required=True, help='Output JSON file or directory (for --by-folder)')
        p_extract.add_argument('--fields', help='Comma-separated list of fields to extract')
        p_extract.add_argument('--incremental', action='store_true', 
                               help='Enable incremental mode (skip unchanged files)')
        p_extract.add_argument('--filter-ftl', action='store_true', default=True,
                               help='Filter out FTL localization keys (default: enabled)')
        p_extract.add_argument('--no-filter-ftl', action='store_true',
                               help='Disable FTL key filtering')
        p_extract.add_argument('--by-folder', action='store_true',
                               help='Generate multiple JSON files by folder structure')
        
        # Merge å‘½ä»¤
        p_merge = subparsers.add_parser('merge', help='Merge translations')
        p_merge.add_argument('--source', required=True, help='Source directory')
        p_merge.add_argument('--input', required=True, help='Input JSON file')
        p_merge.add_argument('--output', required=True, help='Output directory')
        p_merge.add_argument('--fields', help='Comma-separated list of fields to merge')
        
        # Upload å‘½ä»¤
        p_upload = subparsers.add_parser('upload', help='Upload to Paratranz')
        p_upload.add_argument('--file', help='Single file to upload')
        p_upload.add_argument('--folder', help='Folder of JSON files to upload (batch mode)')
        p_upload.add_argument('--project_id', type=int, default=os.environ.get('PZ_PROJECT_ID'))
        p_upload.add_argument('--token', default=os.environ.get('PARATRANZ_TOKEN'))
        
        # Upload-Translation å‘½ä»¤ï¼ˆä¸Šä¼ è¯‘æ–‡ï¼‰
        p_upload_trans = subparsers.add_parser('upload-translation', help='Upload translations to Paratranz')
        p_upload_trans.add_argument('--file', help='Single translation file to upload')
        p_upload_trans.add_argument('--folder', help='Folder of translation JSON files to upload (batch mode)')
        p_upload_trans.add_argument('--force', action='store_true', 
                                    help='Force overwrite translations that have been manually edited')
        p_upload_trans.add_argument('--project_id', type=int, default=os.environ.get('PZ_PROJECT_ID'))
        p_upload_trans.add_argument('--token', default=os.environ.get('PARATRANZ_TOKEN'))
        
        # Download å‘½ä»¤
        p_download = subparsers.add_parser('download', help='Download from Paratranz')
        p_download.add_argument('--file', required=True, help='File to save')
        p_download.add_argument('--remote', help='Remote filename match')
        p_download.add_argument('--project_id', type=int, default=os.environ.get('PZ_PROJECT_ID'))
        p_download.add_argument('--token', default=os.environ.get('PARATRANZ_TOKEN'))
        
        # Workflow å‘½ä»¤
        p_workflow = subparsers.add_parser('workflow', help='Run full workflow')
        p_workflow.add_argument('--scan_dir', required=True, help='Directory to scan')
        p_workflow.add_argument('--output_json', default='en.json', help='Extracted JSON file')
        p_workflow.add_argument('--translation_json', default='zh.json', help='Translation JSON file')
        p_workflow.add_argument('--output_dir', required=True, help='Output directory for merged files')
        p_workflow.add_argument('--project_id', type=int, default=os.environ.get('PZ_PROJECT_ID'))
        p_workflow.add_argument('--token', default=os.environ.get('PARATRANZ_TOKEN'))
        p_workflow.add_argument('--incremental', action='store_true', 
                               help='Enable incremental extraction mode')
        p_workflow.add_argument('--by-folder', action='store_true',
                               help='Generate multiple JSON files by folder structure')
        p_workflow.add_argument('--filter-ftl', action='store_true', default=True,
                               help='Filter out FTL localization keys (default: enabled)')
        p_workflow.add_argument('--no-filter-ftl', action='store_true',
                               help='Disable FTL key filtering')
        
        args = parser.parse_args()
        
        if args.command == 'extract':
            scan_path = args.target_folders
            if args.source:
                scan_path = os.path.join(args.source, args.target_folders)
            fields = args.fields.split(',') if args.fields else None
            filter_ftl = not args.no_filter_ftl  # é»˜è®¤å¼€å¯è¿‡æ»¤
            
            if args.by_folder:
                # æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æ¨¡å¼
                extract_strings_by_folder(scan_path, args.output, fields, 
                                          filter_ftl=filter_ftl)
            else:
                # å•æ–‡ä»¶æ¨¡å¼
                extract_strings(scan_path, args.output, fields, 
                               incremental=args.incremental, filter_ftl=filter_ftl)
            
        elif args.command == 'merge':
            src_path = args.source
            if os.path.exists(os.path.join(src_path, 'Content')):
                src_path = os.path.join(src_path, 'Content')
            fields = args.fields.split(',') if args.fields else None
            merge_translations(src_path, args.input, args.output, fields)
            
        elif args.command == 'upload':
            client = PZClient(args.project_id, args.token)
            if args.folder:
                # æ‰¹é‡ä¸Šä¼ æ¨¡å¼
                client.upload_folder(args.folder)
            elif args.file:
                client.upload_file(args.file)
            else:
                log("è¯·æŒ‡å®š --file æˆ– --folder å‚æ•°", "ERROR")
        
        elif args.command == 'upload-translation':
            client = PZClient(args.project_id, args.token)
            if args.folder:
                # æ‰¹é‡ä¸Šä¼ è¯‘æ–‡æ¨¡å¼
                client.upload_translation_folder(args.folder, force=args.force)
            elif args.file:
                client.upload_translation(args.file, force=args.force)
            else:
                log("è¯·æŒ‡å®š --file æˆ– --folder å‚æ•°", "ERROR")
            
        elif args.command == 'download':
            client = PZClient(args.project_id, args.token)
            client.download_file(args.file, args.remote)
            
        elif args.command == 'workflow':
            filter_ftl = not args.no_filter_ftl
            run_full_workflow(
                args.scan_dir, args.output_json, args.translation_json,
                args.project_id, args.token, args.output_dir,
                fields=None,  # CLIæ¨¡å¼ä½¿ç”¨é»˜è®¤å­—æ®µ
                by_folder=args.by_folder,
                filter_ftl=filter_ftl,
                incremental=args.incremental
            )

